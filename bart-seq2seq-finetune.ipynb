{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:12.839140Z",
     "iopub.status.busy": "2021-02-17T04:04:12.838579Z",
     "iopub.status.idle": "2021-02-17T04:04:13.860820Z",
     "shell.execute_reply": "2021-02-17T04:04:13.860334Z"
    },
    "papermill": {
     "duration": 1.040484,
     "end_time": "2021-02-17T04:04:13.860946",
     "exception": false,
     "start_time": "2021-02-17T04:04:12.820462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/arxiv-title-generation/vocs.pkl\n",
      "/kaggle/input/arxiv-title-generation/train.csv\n",
      "/kaggle/input/arxiv-title-generation/test.csv\n",
      "/kaggle/input/bart3epoch/config.json\n",
      "/kaggle/input/bart3epoch/merges.txt\n",
      "/kaggle/input/bart3epoch/vocab.json\n",
      "/kaggle/input/bart3epoch/tokenizer_config.json\n",
      "/kaggle/input/bart3epoch/pytorch_model.bin\n",
      "/kaggle/input/bart3epoch/special_tokens_map.json\n",
      "/kaggle/input/bartb5/config.json\n",
      "/kaggle/input/bartb5/merges.txt\n",
      "/kaggle/input/bartb5/vocab.json\n",
      "/kaggle/input/bartb5/tokenizer_config.json\n",
      "/kaggle/input/bartb5/pytorch_model.bin\n",
      "/kaggle/input/bartb5/special_tokens_map.json\n",
      "/kaggle/input/bartb41/config.json\n",
      "/kaggle/input/bartb41/merges.txt\n",
      "/kaggle/input/bartb41/vocab.json\n",
      "/kaggle/input/bartb41/tokenizer_config.json\n",
      "/kaggle/input/bartb41/pytorch_model.bin\n",
      "/kaggle/input/bartb41/special_tokens_map.json\n",
      "/kaggle/input/bart-seq2seq-finetune/test.target\n",
      "/kaggle/input/bart-seq2seq-finetune/val.source\n",
      "/kaggle/input/bart-seq2seq-finetune/val.target\n",
      "/kaggle/input/bart-seq2seq-finetune/__results__.html\n",
      "/kaggle/input/bart-seq2seq-finetune/testN.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/test.source\n",
      "/kaggle/input/bart-seq2seq-finetune/__notebook__.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/__output__.json\n",
      "/kaggle/input/bart-seq2seq-finetune/train.target\n",
      "/kaggle/input/bart-seq2seq-finetune/train.source\n",
      "/kaggle/input/bart-seq2seq-finetune/custom.css\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/CONTRIBUTING.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/CODE_OF_CONDUCT.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/valohai.yaml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/setup.cfg\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/LICENSE\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/hubconf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.gitignore\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/Makefile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/pyproject.toml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/MANIFEST.in\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.gitattributes\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.coveragerc\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/ISSUES.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/setup.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_wav2vec2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/conftest.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_common.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_model_card.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_convbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_flax_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_logging.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_hf_argparser.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_deberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_bort.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_benchmark_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_xlm_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_electra.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_fill_mask.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_longformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_configuration_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_wav2vec2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_trainer_distributed.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_flax_common.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_bert_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_activations_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_table_question_answering.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_mobilebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_ner.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_tapas.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_flaubert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_flax_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_feature_extraction.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_trainer_seq2seq.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_zero_shot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_hf_api.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_common.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_utils_check_copies.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_generation_beam_search.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_generation_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_configuration_common.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_retrieval_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_convbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_generation_logits_process.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_optimization.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_layoutlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_electra.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_data_collator.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_common.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_trainer_callback.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_sentiment_analysis.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_blenderbot_small.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_conversational.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_fsmt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_bert_japanese.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_squeezebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_activations.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_small_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_reformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_blenderbot_small.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_trainer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_translation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_squeezebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_mobilebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_flax_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_skip_decorators.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_cli.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_text2text_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_reformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_file_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_fsmt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_flaubert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_versions_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_summarization.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tapas.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_longformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_deberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_mt5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_layoutlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_led.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_mbart50.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_bort.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_trainer_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_xlm_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_bert_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_question_answering.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_optimization_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_model_output.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_benchmark.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_herbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_trainer_tpu.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_encoder_decoder.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_bertweet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_text_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_doc_samples.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_onnx.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_mt5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_pipelines_common.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_led.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_modeling_tf_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_phobert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_barthez.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/test_tokenization_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/sample_text_no_unicode.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/spiece.model\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/test_sentencepiece_no_bos.model\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/test_sentencepiece.model\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/input.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/dummy-config.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/empty.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/sample_text.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/test_sentencepiece_bpe.model\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/.gitignore\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/SQUAD/sample.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/xsum/sample.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/swag/sample.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/wmt16/sample.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/wiki_text/wiki_00\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/GermEval/labels.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/GermEval/train.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/GermEval/dev.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/conll/sample.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/STS-B/dev.tsv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/STS-B/train.tsv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/MRPC/dev.csv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/MRPC/dev.tsv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/MRPC/train.tsv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/tests/fixtures/tests_samples/MRPC/train.csv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/model_cards/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/model_cards/google/tapas-base/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/get_modified_files.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/style_doc.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/check_dummies.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/check_repo.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/check_copies.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/link_tester.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/download_glue_data.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/check_tf_ops.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/check_table.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/utils/tf_ops/onnx.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/check_tokenizers.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/tatoeba/upload_models.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/tatoeba/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/gen-card-allenai-wmt19.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/fsmt-make-super-tiny-model.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/convert-allenai-wmt16.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/eval-facebook-wmt19.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/convert-allenai-wmt19.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/convert-facebook-wmt19.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/fsmt-make-tiny-model.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/tests-to-run.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/gen-card-allenai-wmt16.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/s3-move.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/eval-allenai-wmt16.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/gen-card-facebook-wmt19.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/fsmt/eval-allenai-wmt19.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/scripts/pegasus/build_test_sample_spm_no_bos.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/conftest.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/_tests_requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/test_xla_examples.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/xla_spawn.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/test_examples.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/run_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/run_openai_gpt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/run_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/run_language_modeling.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/run_swag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/run_chinese_ref.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/run_ner.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/lightning_base.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/run_glue.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/run_pos.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/run_ner.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/pytorch-lightning/run_glue.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/run_ner.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/run_pos.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/utils_ner.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/tasks.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/run_chunk.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/run.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/token-classification/scripts/preprocess.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/seq2seq_training_args.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/download_wmt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/old_test_datasets.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/train_mbart_cc25_enro.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/old_test_calculate_rouge.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/finetune_tpu.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/sentence_splitter.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/old_test_tatoeba_conversion.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/minify_dataset.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/save_len_file.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/train_distil_marian_enro.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/pack_dataset.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/run_eval.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/train_distilbart_cnn.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/save_randomly_initialized_model.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/romanian_postprocessing.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/old_test_seq2seq_examples.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/old_test_seq2seq_examples_multi_gpu.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/finetune.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/old_test_fsmt_bleu_score.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/finetune_trainer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/seq2seq_trainer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/convert_model_to_fp16.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/run_distributed_eval.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/train_distil_marian_enro_tpu.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/xla_spawn.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/run_eval_search.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/rouge_cli.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/fsmt/fsmt_val_data.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/fsmt/build-eval-data.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/test.target\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/val.source\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/val.target\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/test.source\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/val.len\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/train.len\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/train.target\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/seq2seq/test_data/wmt_en_ro/train.source\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/multiple_choice/run_multiple_choice.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/multiple_choice/utils_multiple_choice.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/question-answering/run_squad_trainer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/legacy/question-answering/run_squad.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/tests/trainer/test_trainer_ext.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/tests/deepspeed/test_deepspeed.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/tests/deepspeed/ds_config.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mm-imdb/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mm-imdb/utils_mmimdb.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mm-imdb/run_mmimdb.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/adversarial/utils_hans.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/adversarial/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/adversarial/run_hans.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/adversarial/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/test_run_glue_with_pabee.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/run_glue_with_pabee.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/pabee/modeling_pabee_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/pabee/modeling_pabee_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bert-loses-patience/pabee/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/lightning_base.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/_test_seq2seq_examples.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/convert_pl_checkpoint_to_hf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/train_mbart_cc25_enro.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/finetune.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/sentence_splitter.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/run_eval.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/distillation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/finetune_t5.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/train_distilbart_cnn.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/make_student.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/finetune.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/dynamic_bs_example.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/_test_seq2seq_examples_multi_gpu.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/callbacks.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/train_distilbart_xsum.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/_test_bash_script.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/finetune_pegasus_xsum.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/distil_marian_enro_teacher.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/precomputed_pseudo_labels.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/_test_make_student.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/distil_marian_no_teacher.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/seq2seq-distillation/finetune_bart_tiny.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/performer/full_script.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/performer/modeling_flax_performer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/performer/modeling_flax_performer_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/performer/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/performer/run_mlm_performer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/performer/sanity_script.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/entropy_eval.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/train_deebert.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/run_glue_deebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/test_glue_deebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/eval_deebert.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/src/modeling_highway_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/src/modeling_highway_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/deebert/src/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/train.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/run_squad_w_distillation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/distiller.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/grouped_batch_sampler.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/lm_seqs_dataset.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/scripts/extract_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/scripts/extract.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/scripts/token_counts.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/scripts/binarized_data.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/training_configs/distilroberta-base.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/training_configs/distilgpt2.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/training_configs/distilbert-base-cased.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/training_configs/distilbert-base-uncased.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/distillation/training_configs/distilbert-base-multilingual-cased.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/run_pplm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/run_pplm_discrim_train.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/pplm_classification_head.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/imgs/headfigure.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/pplm/imgs/wooly.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mlm_wwm/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mlm_wwm/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mlm_wwm/run_chinese_ref.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/mlm_wwm/run_mlm_wwm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/lightning_base.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/distributed_ray_retriever.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/callbacks_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/test_distributed_retriever.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/consolidate_rag_checkpoint.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/finetune_rag_ray.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/distributed_pytorch_retriever.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/parse_dpr_relevance_data.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/use_own_knowledge_dataset.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/_test_finetune_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/utils_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/finetune_rag.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/eval_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/finetune_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/rag/test_data/my_knowledge_dataset.csv\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/longform-qa/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/longform-qa/eli5_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/longform-qa/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/longform-qa/eli5_app.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/extracting_data.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/modeling_frcnn.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/visualizing_image.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/processing_image.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/lxmert/demo.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/Saving_PruneBERT.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/counts_parameters.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/bertarize.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/masked_run_squad.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/masked_run_glue.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/emmental/configuration_bert_masked.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/emmental/modeling_bert_masked.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/emmental/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/emmental/modules/binarizer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/emmental/modules/masked_nn.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/movement-pruning/emmental/modules/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/test_utils_summarization.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/run_summarization.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/convert_bertabs_original_pytorch_checkpoint.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/utils_summarization.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/configuration_bertabs.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/modeling_bertabs.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertabs/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertology/run_bertology.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertology/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/research_projects/bertology/run_prune_gpt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/token-classification/run_ner.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/token-classification/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/token-classification/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/token-classification/run_tf_ner.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/token-classification/run.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/seq2seq/run_seq2seq.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/seq2seq/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/seq2seq/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/multiple-choice/run_tf_multiple_choice.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/multiple-choice/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/multiple-choice/run_swag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/multiple-choice/utils_multiple_choice.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/multiple-choice/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-generation/run_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-generation/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-generation/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/trainer_qa.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/run_tf_squad.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/run_qa_beam_search.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/utils_qa.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/question-answering/run_qa.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/test_data/wmt_en_ro/train.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/test_data/wmt_en_ro/test.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/test_data/wmt_en_ro/val.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/language-modeling/run_plm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/language-modeling/run_clm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/language-modeling/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/language-modeling/run_mlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/language-modeling/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/language-modeling/run_mlm_flax.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/benchmarking/plot_csv_file.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/benchmarking/run_benchmark_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/benchmarking/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/benchmarking/run_benchmark.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/benchmarking/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-classification/run_tf_text_classification.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-classification/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-classification/run_tf_glue.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-classification/run_xnli.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-classification/requirements.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/examples/text-classification/run_glue.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/stale.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/PULL_REQUEST_TEMPLATE.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/conda/meta.yaml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/conda/build.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/ISSUE_TEMPLATE/question-help.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/ISSUE_TEMPLATE/bug-report.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/ISSUE_TEMPLATE/feature-request.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/ISSUE_TEMPLATE/migration.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/ISSUE_TEMPLATE/---new-benchmark.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/ISSUE_TEMPLATE/--new-model-addition.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/workflows/model-templates.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/workflows/self-push.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/workflows/release-conda.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/workflows/github-torch-hub.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.github/workflows/self-scheduled.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-tensorflow-cpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-pytorch-cpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-pytorch-tpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-pytorch-tpu/dataset.yaml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-pytorch-tpu/docker-entrypoint.sh\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-pytorch-tpu/bert-base-cased.jsonnet\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-gpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-tensorflow-gpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-cpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docker/transformers-pytorch-gpu/Dockerfile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/Makefile\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/philosophy.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/favicon.ico\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/index.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/conf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/preprocessing.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/add_new_model.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/tokenizer_summary.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/training.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_summary.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/task_summary.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_sharing.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/glossary.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/testing.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/converting_tensorflow_models.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/benchmarks.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/multilingual.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/migration.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/perplexity.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/installation.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/bertology.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/quicktour.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/community.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/pretrained_models.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/custom_datasets.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/serialization.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/convbert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/lxmert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/mt5.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/xlnet.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/gpt2.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/electra.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/wav2vec2.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/bertgeneration.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/phobert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/marian.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/auto.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/dialogpt.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/squeezebert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/led.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/gpt.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/reformer.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/prophetnet.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/fsmt.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/bert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/xlm.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/blenderbot_small.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/camembert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/bart.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/funnel.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/t5.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/bertweet.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/xlmprophetnet.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/bort.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/mpnet.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/distilbert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/mbart.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/herbert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/rag.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/deberta.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/pegasus.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/xlmroberta.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/ctrl.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/retribert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/longformer.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/layoutlm.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/transformerxl.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/blenderbot.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/barthez.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/tapas.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/dpr.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/albert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/flaubert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/encoderdecoder.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/mobilebert.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/model_doc/roberta.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/css/Calibre-Regular.otf\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/css/code-snippets.css\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/css/Calibre-Medium.otf\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/css/huggingface.css\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/css/Calibre-Light.ttf\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/css/Calibre-Thin.otf\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/js/huggingface_logo.svg\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/_static/js/custom.js\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/internal/pipelines_utils.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/internal/trainer_utils.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/internal/tokenization_utils.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/internal/generation_utils.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/internal/modeling_utils.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/model.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/processors.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/callback.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/output.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/pipelines.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/logging.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/configuration.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/trainer.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/tokenizer.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/main_classes/optimizer_schedules.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/warmup_cosine_hard_restarts_schedule.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/warmup_cosine_schedule.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/ppl_chunked.gif\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/transformers_overview.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/transformers_logo_name.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/local_attention_mask.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/warmup_linear_schedule.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/ppl_sliding.gif\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/warmup_constant_schedule.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/warmup_cosine_warm_restarts_schedule.png\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/docs/source/imgs/ppl_full.gif\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/ADD_NEW_MODEL_PROPOSAL_TEMPLATE.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/tests/standalone.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/tests/pt-seq-2-seq-bart-tokenizer.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/tests/pt-encoder-bert-tokenizer.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/tests/tf-seq-2-seq-bart-tokenizer.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/tests/encoder-bert-tokenizer.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/tests/tf-encoder-bert-tokenizer.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/open_model_proposals/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/open_model_proposals/ADD_BIG_BIRD.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_tf_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_tf_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/to_replace_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/configuration_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/{{cookiecutter.lowercase_modelname}}.rst\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/tokenization_fast_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/tokenization_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/configuration.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/test_modeling_{{cookiecutter.lowercase_modelname}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_example_script/cookiecutter.json\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_example_script/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/templates/adding_a_new_example_script/{{cookiecutter.directory_name}}/run_{{cookiecutter.example_shortcut}}.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/notebooks/03-pipelines.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/notebooks/04-onnx-export.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/notebooks/05-benchmark.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/notebooks/README.md\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/notebooks/02-transformers.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/notebooks/01-training-tokenizers.ipynb\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/convert_pytorch_checkpoint_to_tf2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/training_args_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modeling_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/generation_beam_search.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modeling_outputs.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/hf_argparser.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/trainer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/convert_slow_tokenizer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/tokenization_utils_base.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/training_args.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/generation_tf_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/file_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/hf_api.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modelcard.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/training_args_seq2seq.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/integrations.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/convert_slow_tokenizers_checkpoints_to_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/trainer_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/convert_tf_hub_seq_to_seq_bert_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/trainer_callback.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/generation_logits_process.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/generation_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/activations_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/convert_graph_to_onnx.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/dependency_versions_check.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/activations.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modeling_tf_pytorch_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/trainer_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/optimization.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/trainer_pt_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/optimization_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modeling_tf_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/tokenization_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/tokenization_utils_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/dependency_versions_table.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/configuration_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modeling_flax_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/modeling_tf_outputs.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/testing_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/trainer_seq2seq.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/dummy_pt_objects.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/dummy_tokenizers_objects.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/versions.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/dummy_tf_objects.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/model_parallel_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/dummy_sentencepiece_objects.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/notebook.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/sentencepiece_model_pb2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/logging.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/dummy_flax_objects.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/utils/hp_naming.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/train.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/run.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/add_new_model.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/env.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/lfs.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/convert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/user.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/serving.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/download.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/transformers_cli.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/commands/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/barthez/tokenization_barthez_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/barthez/tokenization_barthez.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/barthez/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/configuration_mobilebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/tokenization_mobilebert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/modeling_tf_mobilebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/modeling_mobilebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/convert_mobilebert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mobilebert/tokenization_mobilebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/phobert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/phobert/tokenization_phobert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/modeling_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/modeling_tf_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/tokenization_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/configuration_t5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/tokenization_t5_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/t5/convert_t5_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/retribert/tokenization_retribert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/retribert/tokenization_retribert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/retribert/modeling_retribert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/retribert/configuration_retribert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/retribert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_roberta/modeling_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_roberta/modeling_tf_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_roberta/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_roberta/tokenization_xlm_roberta_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_roberta/configuration_xlm_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/fsmt/tokenization_fsmt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/fsmt/configuration_fsmt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/fsmt/convert_fsmt_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/fsmt/modeling_fsmt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/fsmt/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/prophetnet/tokenization_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/prophetnet/configuration_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/prophetnet/modeling_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/prophetnet/convert_prophetnet_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/prophetnet/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/layoutlm/modeling_layoutlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/layoutlm/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/layoutlm/tokenization_layoutlm_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/layoutlm/configuration_layoutlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/layoutlm/tokenization_layoutlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/reformer/tokenization_reformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/reformer/modeling_reformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/reformer/tokenization_reformer_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/reformer/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/reformer/configuration_reformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/reformer/convert_reformer_trax_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/configuration_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/convert_openai_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/modeling_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/tokenization_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/tokenization_openai_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/openai/modeling_tf_openai.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot/convert_blenderbot_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot/modeling_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot/configuration_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot/modeling_tf_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot/tokenization_blenderbot.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/tapas/configuration_tapas.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/tapas/modeling_tapas.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/tapas/tokenization_tapas.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/tapas/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/tapas/convert_tapas_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/flaubert/configuration_flaubert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/flaubert/modeling_flaubert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/flaubert/tokenization_flaubert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/flaubert/modeling_tf_flaubert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/flaubert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/encoder_decoder/configuration_encoder_decoder.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/encoder_decoder/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/convert_bert_original_tf2_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/tokenization_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/convert_bert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/configuration_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/modeling_tf_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/tokenization_bert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/modeling_flax_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/convert_bert_pytorch_checkpoint_to_original_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/modeling_bert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dialogpt/convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dialogpt/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/configuration_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/tokenization_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/convert_dpr_original_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/modeling_tf_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/modeling_dpr.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/dpr/tokenization_dpr_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/auto/tokenization_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/auto/modeling_flax_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/auto/modeling_tf_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/auto/modeling_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/auto/configuration_auto.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/auto/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/modeling_convbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/configuration_convbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/tokenization_convbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/tokenization_convbert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/convert_convbert_original_tf1_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/convbert/modeling_tf_convbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/squeezebert/tokenization_squeezebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/squeezebert/modeling_squeezebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/squeezebert/tokenization_squeezebert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/squeezebert/configuration_squeezebert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/squeezebert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bertweet/tokenization_bertweet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bertweet/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/tokenization_xlnet_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/modeling_tf_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/tokenization_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/configuration_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/convert_xlnet_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlnet/modeling_xlnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert_generation/modeling_bert_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert_generation/configuration_bert_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert_generation/tokenization_bert_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert_generation/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/led/tokenization_led.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/led/modeling_led.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/led/configuration_led.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/led/modeling_tf_led.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/led/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/led/tokenization_led_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/wav2vec2/configuration_wav2vec2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/wav2vec2/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/modeling_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/modeling_tf_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/convert_marian_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/configuration_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/convert_marian_tatoeba_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/marian/tokenization_marian.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/modeling_tf_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/convert_albert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/modeling_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/tokenization_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/configuration_albert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/albert/tokenization_albert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/distilbert/configuration_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/distilbert/modeling_tf_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/distilbert/tokenization_distilbert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/distilbert/tokenization_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/distilbert/modeling_distilbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/distilbert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/tokenization_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/modeling_transfo_xl_utilities.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/modeling_tf_transfo_xl_utilities.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/convert_transfo_xl_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/configuration_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/modeling_tf_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/transfo_xl/modeling_transfo_xl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/herbert/tokenization_herbert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/herbert/tokenization_herbert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/herbert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bort/convert_bort_original_gluonnlp_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot_small/modeling_blenderbot_small.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot_small/modeling_tf_blenderbot_small.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot_small/configuration_blenderbot_small.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot_small/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/blenderbot_small/tokenization_blenderbot_small_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/ctrl/tokenization_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/ctrl/configuration_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/ctrl/modeling_tf_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/ctrl/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/ctrl/modeling_ctrl.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/deberta/modeling_deberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/deberta/tokenization_deberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/deberta/configuration_deberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/deberta/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/rag/retrieval_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/rag/tokenization_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/rag/configuration_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/rag/modeling_rag.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/rag/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mpnet/modeling_tf_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mpnet/modeling_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mpnet/configuration_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mpnet/tokenization_mpnet_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mpnet/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mpnet/tokenization_mpnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/modeling_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/tokenization_gpt2_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/configuration_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/modeling_tf_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/tokenization_gpt2.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/gpt2/convert_gpt2_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/tokenization_pegasus_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/tokenization_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/convert_pegasus_tf_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/modeling_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/configuration_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/modeling_tf_pegasus.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/pegasus/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mt5/modeling_tf_mt5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mt5/configuration_mt5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mt5/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mt5/modeling_mt5.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/modeling_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/tokenization_roberta_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/modeling_tf_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/configuration_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/tokenization_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/convert_roberta_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/roberta/modeling_flax_roberta.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/configuration_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/modeling_tf_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/modeling_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/convert_funnel_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/tokenization_funnel.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/tokenization_funnel_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/funnel/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/tokenization_bart_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/configuration_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/convert_bart_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/modeling_tf_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/modeling_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bart/tokenization_bart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/tokenization_longformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/convert_longformer_original_pytorch_lightning_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/modeling_longformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/modeling_tf_longformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/configuration_longformer.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/longformer/tokenization_longformer_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/tokenization_electra.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/configuration_electra.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/modeling_electra.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/modeling_tf_electra.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/convert_electra_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/tokenization_electra_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/electra/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert_japanese/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/bert_japanese/tokenization_bert_japanese.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_prophetnet/tokenization_xlm_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_prophetnet/configuration_xlm_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_prophetnet/modeling_xlm_prophetnet.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm_prophetnet/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/convert_lxmert_original_tf_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/tokenization_lxmert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/configuration_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/modeling_tf_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/modeling_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/lxmert/tokenization_lxmert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm/modeling_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm/convert_xlm_original_pytorch_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm/configuration_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm/tokenization_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/xlm/modeling_tf_xlm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/tokenization_mbart50_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/tokenization_mbart_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/tokenization_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/modeling_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/modeling_tf_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/tokenization_mbart50.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/convert_mbart_original_checkpoint_to_pytorch.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mbart/configuration_mbart.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/camembert/modeling_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/camembert/configuration_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/camembert/tokenization_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/camembert/modeling_tf_camembert.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/camembert/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/camembert/tokenization_camembert_fast.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mmbt/configuration_mmbt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mmbt/modeling_mmbt.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/models/mmbt/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/question_answering.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/zero_shot_classification.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/base.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/text_classification.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/token_classification.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/feature_extraction.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/text_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/conversational.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/fill_mask.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/text2text_generation.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/pipelines/table_question_answering.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/benchmark_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/benchmark_args_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/benchmark.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/benchmark_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/benchmark_args.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/benchmark/benchmark_args_tf.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/sagemaker/trainer_sm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/sagemaker/training_args_sm.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/sagemaker/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/test_generation_utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/data_collator.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/processors/xnli.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/processors/utils.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/processors/squad.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/processors/glue.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/processors/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/datasets/squad.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/datasets/language_modeling.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/datasets/glue.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/datasets/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/metrics/squad_metrics.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers/data/metrics/__init__.py\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers.egg-info/entry_points.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers.egg-info/dependency_links.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers.egg-info/SOURCES.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers.egg-info/requires.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers.egg-info/top_level.txt\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/src/transformers.egg-info/PKG-INFO\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/config\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/packed-refs\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/HEAD\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/index\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/description\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/info/exclude\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/refs/heads/master\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/refs/remotes/origin/HEAD\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/prepare-commit-msg.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/update.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/pre-push.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/pre-rebase.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/pre-applypatch.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/pre-commit.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/commit-msg.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/post-update.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/pre-receive.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/fsmonitor-watchman.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/hooks/applypatch-msg.sample\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/logs/HEAD\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/logs/refs/heads/master\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/logs/refs/remotes/origin/HEAD\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/objects/pack/pack-79305dbb81b7921efd4b5ec550723c3f19c3b91d.idx\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.git/objects/pack/pack-79305dbb81b7921efd4b5ec550723c3f19c3b91d.pack\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.circleci/config.yml\n",
      "/kaggle/input/bart-seq2seq-finetune/transformers/.circleci/deploy.sh\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:13.898434Z",
     "iopub.status.busy": "2021-02-17T04:04:13.897415Z",
     "iopub.status.idle": "2021-02-17T04:04:24.638023Z",
     "shell.execute_reply": "2021-02-17T04:04:24.636843Z"
    },
    "papermill": {
     "duration": 10.762886,
     "end_time": "2021-02-17T04:04:24.638138",
     "exception": false,
     "start_time": "2021-02-17T04:04:13.875252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/arxiv-title-generation/'\n",
    "outPath = './'\n",
    "dataPd = pd.read_csv(path + \"train.csv\", engine='python', encoding='utf-8', error_bad_lines=False) \n",
    "\n",
    "#dataPd.to_csv(\"/content/drive/MyDrive/kaggle/title-generation/train_pd.csv\", index=False)\n",
    "trainL = int((len(dataPd)*0.95)//1)\n",
    "valL = int((len(dataPd)*0.05)//2)\n",
    "testL = int(len(dataPd) - trainL - valL)\n",
    "dataPd.loc[:trainL, 'abstract'].to_csv(outPath + \"train.source\", index=False)\n",
    "dataPd.loc[:trainL, 'title'].to_csv(outPath + \"train.target\", index=False)\n",
    "dataPd.loc[trainL:trainL + valL, 'abstract'].to_csv(outPath + \"val.source\", index=False)\n",
    "dataPd.loc[trainL:trainL + valL, 'title'].to_csv(outPath + \"val.target\", index=False)\n",
    "dataPd.loc[trainL + valL:, 'abstract'].to_csv(outPath + \"test.source\", index=False)\n",
    "dataPd.loc[trainL + valL:, 'title'].to_csv(outPath + \"test.target\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:24.671436Z",
     "iopub.status.busy": "2021-02-17T04:04:24.670859Z",
     "iopub.status.idle": "2021-02-17T04:04:24.716095Z",
     "shell.execute_reply": "2021-02-17T04:04:24.715610Z"
    },
    "papermill": {
     "duration": 0.063978,
     "end_time": "2021-02-17T04:04:24.716204",
     "exception": false,
     "start_time": "2021-02-17T04:04:24.652226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/arxiv-title-generation/'\n",
    "testDf = pd.read_csv(path + \"test.csv\", engine='python', encoding='utf-8', error_bad_lines=False)\n",
    "#testDf['abstract'].to_csv('./test.csv',index=False)\n",
    "abstracts = testDf['abstract'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:24.765989Z",
     "iopub.status.busy": "2021-02-17T04:04:24.755728Z",
     "iopub.status.idle": "2021-02-17T04:04:24.987752Z",
     "shell.execute_reply": "2021-02-17T04:04:24.987263Z"
    },
    "papermill": {
     "duration": 0.257947,
     "end_time": "2021-02-17T04:04:24.987858",
     "exception": false,
     "start_time": "2021-02-17T04:04:24.729911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range(len(abstracts)):\n",
    "    for j in range(len(abstracts[i])):\n",
    "        if abstracts[i][j] == '\\n':\n",
    "            c += 1 \n",
    "            abstracts[i] = abstracts[i][:j] + ' ' + abstracts[i][j+1:]\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:25.021436Z",
     "iopub.status.busy": "2021-02-17T04:04:25.020578Z",
     "iopub.status.idle": "2021-02-17T04:04:25.026675Z",
     "shell.execute_reply": "2021-02-17T04:04:25.026230Z"
    },
    "papermill": {
     "duration": 0.025042,
     "end_time": "2021-02-17T04:04:25.026761",
     "exception": false,
     "start_time": "2021-02-17T04:04:25.001719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = open('./testN.txt', 'w')\n",
    "for i in abstracts:\n",
    "    f.write(i + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:25.059734Z",
     "iopub.status.busy": "2021-02-17T04:04:25.058962Z",
     "iopub.status.idle": "2021-02-17T04:04:27.514701Z",
     "shell.execute_reply": "2021-02-17T04:04:27.513634Z"
    },
    "papermill": {
     "duration": 2.474028,
     "end_time": "2021-02-17T04:04:27.514842",
     "exception": false,
     "start_time": "2021-02-17T04:04:25.040814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'transformers'...\r\n",
      "remote: Enumerating objects: 1182, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1182/1182), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (1003/1003), done.\u001b[K\r\n",
      "remote: Total 1182 (delta 330), reused 391 (delta 147), pack-reused 0\u001b[K\r\n",
      "Receiving objects: 100% (1182/1182), 6.26 MiB | 17.70 MiB/s, done.\r\n",
      "Resolving deltas: 100% (330/330), done.\r\n",
      "Note: checking out 'cd48078ce59a195473729759c76d88ae612b0f7a'.\r\n",
      "\r\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\r\n",
      "changes and commit them, and you can discard any commits you make in this\r\n",
      "state without impacting any branches by performing another checkout.\r\n",
      "\r\n",
      "If you want to create a new branch to retain commits you create, you may\r\n",
      "do so (now or later) by using -b with the checkout command again. Example:\r\n",
      "\r\n",
      "  git checkout -b <new-branch-name>\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!git clone --depth 1 --branch v4.3.2 https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:27.571191Z",
     "iopub.status.busy": "2021-02-17T04:04:27.565439Z",
     "iopub.status.idle": "2021-02-17T04:04:48.863482Z",
     "shell.execute_reply": "2021-02-17T04:04:48.862631Z"
    },
    "papermill": {
     "duration": 21.326996,
     "end_time": "2021-02-17T04:04:48.863601",
     "exception": false,
     "start_time": "2021-02-17T04:04:27.536605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GitPython in /opt/conda/lib/python3.7/site-packages (3.1.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython) (4.0.4)\r\n",
      "Requirement already satisfied: smmap<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython) (3.0.2)\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting rouge-score\r\n",
      "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.18.5)\r\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.7/site-packages (from rouge-score) (0.10.0)\r\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from rouge-score) (3.2.4)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.14.0)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.14.0)\r\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from rouge-score) (1.14.0)\r\n",
      "Installing collected packages: rouge-score\r\n",
      "Successfully installed rouge-score-0.0.4\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n",
      "Collecting sacrebleu\r\n",
      "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\r\n",
      "\u001b[K     || 65 kB 2.1 MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.0.0)\r\n",
      "Installing collected packages: sacrebleu\r\n",
      "Successfully installed sacrebleu-1.5.0\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install GitPython\n",
    "!pip install rouge-score\n",
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:04:48.919458Z",
     "iopub.status.busy": "2021-02-17T04:04:48.918606Z",
     "iopub.status.idle": "2021-02-17T04:05:05.524056Z",
     "shell.execute_reply": "2021-02-17T04:05:05.523184Z"
    },
    "papermill": {
     "duration": 16.63479,
     "end_time": "2021-02-17T04:05:05.524194",
     "exception": false,
     "start_time": "2021-02-17T04:04:48.889404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: typing 3.7.4.3\r\n",
      "Uninstalling typing-3.7.4.3:\r\n",
      "  Successfully uninstalled typing-3.7.4.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:05:05.584369Z",
     "iopub.status.busy": "2021-02-17T04:05:05.583588Z",
     "iopub.status.idle": "2021-02-17T04:05:23.268322Z",
     "shell.execute_reply": "2021-02-17T04:05:23.267401Z"
    },
    "papermill": {
     "duration": 17.717729,
     "end_time": "2021-02-17T04:05:23.268439",
     "exception": false,
     "start_time": "2021-02-17T04:05:05.550710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///kaggle/working/transformers\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (0.0.43)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (4.45.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (2020.4.4)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (3.0.10)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (3.1.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (1.18.5)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (2.23.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (20.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.3.2) (3.1.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.3.2) (1.14.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.3.2) (2.4.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.3.2) (2020.12.5)\r\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.3.2) (2.9)\r\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.3.2) (3.0.4)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.3.2) (1.25.9)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->transformers==4.3.2) (1.14.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (2020.4.4)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.3.2) (7.1.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.3.2) (4.45.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==4.3.2) (0.14.1)\r\n",
      "Collecting tokenizers<0.11,>=0.10.1\r\n",
      "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\r\n",
      "\u001b[K     || 3.2 MB 4.3 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: tokenizers, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.9.3\r\n",
      "    Uninstalling tokenizers-0.9.3:\r\n",
      "      Successfully uninstalled tokenizers-0.9.3\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 3.5.1\r\n",
      "    Uninstalling transformers-3.5.1:\r\n",
      "      Successfully uninstalled transformers-3.5.1\r\n",
      "  Running setup.py develop for transformers\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "allennlp 1.2.2 requires transformers<3.6,>=3.4, but you have transformers 4.3.2 which is incompatible.\u001b[0m\r\n",
      "Successfully installed tokenizers-0.10.1 transformers\r\n",
      "\u001b[33mWARNING: You are using pip version 20.3.1; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -e '/kaggle/working/transformers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:05:23.352450Z",
     "iopub.status.busy": "2021-02-17T04:05:23.350251Z",
     "iopub.status.idle": "2021-02-17T04:05:23.353418Z",
     "shell.execute_reply": "2021-02-17T04:05:23.354099Z"
    },
    "papermill": {
     "duration": 0.051065,
     "end_time": "2021-02-17T04:05:23.354286",
     "exception": false,
     "start_time": "2021-02-17T04:05:23.303221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!python3 /kaggle/working/transformers/examples/seq2seq/finetune_trainer.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T04:05:23.444084Z",
     "iopub.status.busy": "2021-02-17T04:05:23.439470Z",
     "iopub.status.idle": "2021-02-17T09:59:07.730151Z",
     "shell.execute_reply": "2021-02-17T09:59:07.660750Z"
    },
    "papermill": {
     "duration": 21224.332947,
     "end_time": "2021-02-17T09:59:07.730276",
     "exception": false,
     "start_time": "2021-02-17T04:05:23.397329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-02-17 04:05:28.599745: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "[INFO|configuration_utils.py:447] 2021-02-17 04:05:33,846 >> loading configuration file /kaggle/input/bartb5/config.json\r\n",
      "[INFO|configuration_utils.py:485] 2021-02-17 04:05:33,847 >> Model config BartConfig {\r\n",
      "  \"_name_or_path\": \"/kaggle/input/bart-seq2seq-finetune/\",\r\n",
      "  \"_num_labels\": 3,\r\n",
      "  \"activation_dropout\": 0.0,\r\n",
      "  \"activation_function\": \"gelu\",\r\n",
      "  \"add_bias_logits\": false,\r\n",
      "  \"add_final_layer_norm\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"BartForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"classif_dropout\": 0.0,\r\n",
      "  \"classifier_dropout\": 0.0,\r\n",
      "  \"d_model\": 1024,\r\n",
      "  \"decoder_attention_heads\": 16,\r\n",
      "  \"decoder_ffn_dim\": 4096,\r\n",
      "  \"decoder_layerdrop\": 0.0,\r\n",
      "  \"decoder_layers\": 6,\r\n",
      "  \"decoder_start_token_id\": 2,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": true,\r\n",
      "  \"encoder_attention_heads\": 16,\r\n",
      "  \"encoder_ffn_dim\": 4096,\r\n",
      "  \"encoder_layerdrop\": 0.0,\r\n",
      "  \"encoder_layers\": 12,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"eos_token_ids\": [\r\n",
      "    2\r\n",
      "  ],\r\n",
      "  \"extra_pos_embeddings\": 2,\r\n",
      "  \"force_bos_token_to_be_generated\": false,\r\n",
      "  \"forced_eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"init_std\": 0.02,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"length_penalty\": 0.5,\r\n",
      "  \"max_length\": 62,\r\n",
      "  \"max_position_embeddings\": 1024,\r\n",
      "  \"min_length\": 11,\r\n",
      "  \"model_type\": \"bart\",\r\n",
      "  \"no_repeat_ngram_size\": 3,\r\n",
      "  \"normalize_before\": false,\r\n",
      "  \"normalize_embedding\": true,\r\n",
      "  \"num_beams\": 6,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"prefix\": \" \",\r\n",
      "  \"replacing_rate\": 0,\r\n",
      "  \"save_step\": 58,\r\n",
      "  \"scale_embedding\": false,\r\n",
      "  \"static_position_embeddings\": false,\r\n",
      "  \"student_decoder_layers\": null,\r\n",
      "  \"student_encoder_layers\": null,\r\n",
      "  \"task_specific_params\": {},\r\n",
      "  \"transformers_version\": \"4.3.2\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 50264\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|configuration_utils.py:447] 2021-02-17 04:05:33,848 >> loading configuration file /kaggle/input/bartb5/config.json\r\n",
      "[INFO|configuration_utils.py:485] 2021-02-17 04:05:33,849 >> Model config BartConfig {\r\n",
      "  \"_name_or_path\": \"/kaggle/input/bart-seq2seq-finetune/\",\r\n",
      "  \"_num_labels\": 3,\r\n",
      "  \"activation_dropout\": 0.0,\r\n",
      "  \"activation_function\": \"gelu\",\r\n",
      "  \"add_bias_logits\": false,\r\n",
      "  \"add_final_layer_norm\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"BartForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"classif_dropout\": 0.0,\r\n",
      "  \"classifier_dropout\": 0.0,\r\n",
      "  \"d_model\": 1024,\r\n",
      "  \"decoder_attention_heads\": 16,\r\n",
      "  \"decoder_ffn_dim\": 4096,\r\n",
      "  \"decoder_layerdrop\": 0.0,\r\n",
      "  \"decoder_layers\": 6,\r\n",
      "  \"decoder_start_token_id\": 2,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": true,\r\n",
      "  \"encoder_attention_heads\": 16,\r\n",
      "  \"encoder_ffn_dim\": 4096,\r\n",
      "  \"encoder_layerdrop\": 0.0,\r\n",
      "  \"encoder_layers\": 12,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"eos_token_ids\": [\r\n",
      "    2\r\n",
      "  ],\r\n",
      "  \"extra_pos_embeddings\": 2,\r\n",
      "  \"force_bos_token_to_be_generated\": false,\r\n",
      "  \"forced_eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"init_std\": 0.02,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"length_penalty\": 0.5,\r\n",
      "  \"max_length\": 62,\r\n",
      "  \"max_position_embeddings\": 1024,\r\n",
      "  \"min_length\": 11,\r\n",
      "  \"model_type\": \"bart\",\r\n",
      "  \"no_repeat_ngram_size\": 3,\r\n",
      "  \"normalize_before\": false,\r\n",
      "  \"normalize_embedding\": true,\r\n",
      "  \"num_beams\": 6,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"prefix\": \" \",\r\n",
      "  \"replacing_rate\": 0,\r\n",
      "  \"save_step\": 58,\r\n",
      "  \"scale_embedding\": false,\r\n",
      "  \"static_position_embeddings\": false,\r\n",
      "  \"student_decoder_layers\": null,\r\n",
      "  \"student_encoder_layers\": null,\r\n",
      "  \"task_specific_params\": {},\r\n",
      "  \"transformers_version\": \"4.3.2\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 50264\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|tokenization_utils_base.py:1688] 2021-02-17 04:05:33,849 >> Model name '/kaggle/input/bartb5/' not found in model shortcut name list (facebook/bart-base, facebook/bart-large, facebook/bart-large-mnli, facebook/bart-large-cnn, facebook/bart-large-xsum, yjernite/bart_eli5). Assuming '/kaggle/input/bartb5/' is a path, a model identifier, or url to a directory containing tokenizer files.\r\n",
      "[INFO|tokenization_utils_base.py:1721] 2021-02-17 04:05:33,853 >> Didn't find file /kaggle/input/bartb5/tokenizer.json. We won't load it.\r\n",
      "[INFO|tokenization_utils_base.py:1721] 2021-02-17 04:05:33,853 >> Didn't find file /kaggle/input/bartb5/added_tokens.json. We won't load it.\r\n",
      "[INFO|tokenization_utils_base.py:1784] 2021-02-17 04:05:33,856 >> loading file /kaggle/input/bartb5/vocab.json\r\n",
      "[INFO|tokenization_utils_base.py:1784] 2021-02-17 04:05:33,856 >> loading file /kaggle/input/bartb5/merges.txt\r\n",
      "[INFO|tokenization_utils_base.py:1784] 2021-02-17 04:05:33,856 >> loading file None\r\n",
      "[INFO|tokenization_utils_base.py:1784] 2021-02-17 04:05:33,856 >> loading file None\r\n",
      "[INFO|tokenization_utils_base.py:1784] 2021-02-17 04:05:33,856 >> loading file /kaggle/input/bartb5/special_tokens_map.json\r\n",
      "[INFO|tokenization_utils_base.py:1784] 2021-02-17 04:05:33,856 >> loading file /kaggle/input/bartb5/tokenizer_config.json\r\n",
      "[INFO|modeling_utils.py:1025] 2021-02-17 04:05:34,035 >> loading weights file /kaggle/input/bartb5/pytorch_model.bin\r\n",
      "[INFO|modeling_utils.py:1143] 2021-02-17 04:06:00,428 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\r\n",
      "\r\n",
      "[INFO|modeling_utils.py:1152] 2021-02-17 04:06:00,428 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /kaggle/input/bartb5/.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\r\n",
      "[WARNING|integrations.py:514] 2021-02-17 04:06:07,042 >> W&B installed but not logged in. Run `wandb login` or set the WANDB_API_KEY env variable.\r\n",
      "/kaggle/working/transformers/src/transformers/trainer.py:705: FutureWarning: `model_path` is deprecated and will be removed in a future version. Use `resume_from_checkpoint` instead.\r\n",
      "  FutureWarning,\r\n",
      "[INFO|trainer.py:724] 2021-02-17 04:06:07,044 >> Loading model from /kaggle/input/bartb5/).\r\n",
      "[INFO|configuration_utils.py:447] 2021-02-17 04:06:07,047 >> loading configuration file /kaggle/input/bartb5/config.json\r\n",
      "[INFO|configuration_utils.py:485] 2021-02-17 04:06:07,048 >> Model config BartConfig {\r\n",
      "  \"_name_or_path\": \"/kaggle/input/bart-seq2seq-finetune/\",\r\n",
      "  \"_num_labels\": 3,\r\n",
      "  \"activation_dropout\": 0.0,\r\n",
      "  \"activation_function\": \"gelu\",\r\n",
      "  \"add_bias_logits\": false,\r\n",
      "  \"add_final_layer_norm\": false,\r\n",
      "  \"architectures\": [\r\n",
      "    \"BartForConditionalGeneration\"\r\n",
      "  ],\r\n",
      "  \"attention_dropout\": 0.0,\r\n",
      "  \"bos_token_id\": 0,\r\n",
      "  \"classif_dropout\": 0.0,\r\n",
      "  \"classifier_dropout\": 0.0,\r\n",
      "  \"d_model\": 1024,\r\n",
      "  \"decoder_attention_heads\": 16,\r\n",
      "  \"decoder_ffn_dim\": 4096,\r\n",
      "  \"decoder_layerdrop\": 0.0,\r\n",
      "  \"decoder_layers\": 6,\r\n",
      "  \"decoder_start_token_id\": 2,\r\n",
      "  \"dropout\": 0.1,\r\n",
      "  \"early_stopping\": true,\r\n",
      "  \"encoder_attention_heads\": 16,\r\n",
      "  \"encoder_ffn_dim\": 4096,\r\n",
      "  \"encoder_layerdrop\": 0.0,\r\n",
      "  \"encoder_layers\": 12,\r\n",
      "  \"eos_token_id\": 2,\r\n",
      "  \"eos_token_ids\": [\r\n",
      "    2\r\n",
      "  ],\r\n",
      "  \"extra_pos_embeddings\": 2,\r\n",
      "  \"force_bos_token_to_be_generated\": false,\r\n",
      "  \"forced_eos_token_id\": 2,\r\n",
      "  \"gradient_checkpointing\": false,\r\n",
      "  \"id2label\": {\r\n",
      "    \"0\": \"LABEL_0\",\r\n",
      "    \"1\": \"LABEL_1\",\r\n",
      "    \"2\": \"LABEL_2\"\r\n",
      "  },\r\n",
      "  \"init_std\": 0.02,\r\n",
      "  \"is_encoder_decoder\": true,\r\n",
      "  \"label2id\": {\r\n",
      "    \"LABEL_0\": 0,\r\n",
      "    \"LABEL_1\": 1,\r\n",
      "    \"LABEL_2\": 2\r\n",
      "  },\r\n",
      "  \"length_penalty\": 0.5,\r\n",
      "  \"max_length\": 62,\r\n",
      "  \"max_position_embeddings\": 1024,\r\n",
      "  \"min_length\": 11,\r\n",
      "  \"model_type\": \"bart\",\r\n",
      "  \"no_repeat_ngram_size\": 3,\r\n",
      "  \"normalize_before\": false,\r\n",
      "  \"normalize_embedding\": true,\r\n",
      "  \"num_beams\": 6,\r\n",
      "  \"num_hidden_layers\": 12,\r\n",
      "  \"output_past\": true,\r\n",
      "  \"pad_token_id\": 1,\r\n",
      "  \"prefix\": \" \",\r\n",
      "  \"replacing_rate\": 0,\r\n",
      "  \"save_step\": 58,\r\n",
      "  \"scale_embedding\": false,\r\n",
      "  \"static_position_embeddings\": false,\r\n",
      "  \"student_decoder_layers\": null,\r\n",
      "  \"student_encoder_layers\": null,\r\n",
      "  \"task_specific_params\": {},\r\n",
      "  \"transformers_version\": \"4.3.2\",\r\n",
      "  \"use_cache\": true,\r\n",
      "  \"vocab_size\": 50264\r\n",
      "}\r\n",
      "\r\n",
      "[INFO|modeling_utils.py:1025] 2021-02-17 04:06:07,048 >> loading weights file /kaggle/input/bartb5/pytorch_model.bin\r\n",
      "[INFO|modeling_utils.py:1143] 2021-02-17 04:06:23,186 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\r\n",
      "\r\n",
      "[INFO|modeling_utils.py:1152] 2021-02-17 04:06:23,186 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /kaggle/input/bartb5/.\r\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\r\n",
      "[INFO|trainer.py:837] 2021-02-17 04:06:23,534 >> ***** Running training *****\r\n",
      "[INFO|trainer.py:838] 2021-02-17 04:06:23,534 >>   Num examples = 128251\r\n",
      "[INFO|trainer.py:839] 2021-02-17 04:06:23,534 >>   Num Epochs = 1\r\n",
      "[INFO|trainer.py:840] 2021-02-17 04:06:23,534 >>   Instantaneous batch size per device = 1\r\n",
      "[INFO|trainer.py:841] 2021-02-17 04:06:23,534 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\r\n",
      "[INFO|trainer.py:842] 2021-02-17 04:06:23,534 >>   Gradient Accumulation steps = 1\r\n",
      "[INFO|trainer.py:843] 2021-02-17 04:06:23,534 >>   Total optimization steps = 128251\r\n",
      "{'loss': 0.1708, 'learning_rate': 4.9805069746044866e-09, 'epoch': 0.0}\r\n",
      "{'loss': 0.2122, 'learning_rate': 4.961013949208973e-09, 'epoch': 0.01}\r\n",
      "{'loss': 0.202, 'learning_rate': 4.9415209238134595e-09, 'epoch': 0.01}\r\n",
      "{'loss': 0.1916, 'learning_rate': 4.922027898417946e-09, 'epoch': 0.02}\r\n",
      "{'loss': 0.1686, 'learning_rate': 4.902534873022433e-09, 'epoch': 0.02}\r\n",
      "{'loss': 0.2018, 'learning_rate': 4.883041847626919e-09, 'epoch': 0.02}\r\n",
      "{'loss': 0.1945, 'learning_rate': 4.863548822231405e-09, 'epoch': 0.03}\r\n",
      "{'loss': 0.1919, 'learning_rate': 4.8440557968358925e-09, 'epoch': 0.03}\r\n",
      "{'loss': 0.2105, 'learning_rate': 4.824562771440379e-09, 'epoch': 0.04}\r\n",
      "{'loss': 0.2011, 'learning_rate': 4.8050697460448654e-09, 'epoch': 0.04}\r\n",
      "{'loss': 0.1539, 'learning_rate': 4.785576720649352e-09, 'epoch': 0.04}\r\n",
      "{'loss': 0.2172, 'learning_rate': 4.766083695253838e-09, 'epoch': 0.05}\r\n",
      "{'loss': 0.2277, 'learning_rate': 4.746590669858325e-09, 'epoch': 0.05}\r\n",
      "{'loss': 0.2128, 'learning_rate': 4.727097644462811e-09, 'epoch': 0.05}\r\n",
      "{'loss': 0.1782, 'learning_rate': 4.707604619067298e-09, 'epoch': 0.06}\r\n",
      "{'loss': 0.2065, 'learning_rate': 4.688111593671784e-09, 'epoch': 0.06}\r\n",
      "{'loss': 0.2124, 'learning_rate': 4.668618568276271e-09, 'epoch': 0.07}\r\n",
      "{'loss': 0.2219, 'learning_rate': 4.649125542880757e-09, 'epoch': 0.07}\r\n",
      "{'loss': 0.1927, 'learning_rate': 4.6296325174852435e-09, 'epoch': 0.07}\r\n",
      "{'loss': 0.1495, 'learning_rate': 4.610139492089731e-09, 'epoch': 0.08}\r\n",
      "{'loss': 0.2028, 'learning_rate': 4.590646466694217e-09, 'epoch': 0.08}\r\n",
      "{'loss': 0.2067, 'learning_rate': 4.571153441298704e-09, 'epoch': 0.09}\r\n",
      "{'loss': 0.2058, 'learning_rate': 4.55166041590319e-09, 'epoch': 0.09}\r\n",
      "{'loss': 0.1946, 'learning_rate': 4.5321673905076765e-09, 'epoch': 0.09}\r\n",
      "{'loss': 0.2095, 'learning_rate': 4.512674365112163e-09, 'epoch': 0.1}\r\n",
      "{'loss': 0.2203, 'learning_rate': 4.4931813397166494e-09, 'epoch': 0.1}\r\n",
      "{'loss': 0.2029, 'learning_rate': 4.473688314321136e-09, 'epoch': 0.11}\r\n",
      "{'loss': 0.2056, 'learning_rate': 4.454195288925622e-09, 'epoch': 0.11}\r\n",
      "{'loss': 0.2107, 'learning_rate': 4.434702263530109e-09, 'epoch': 0.11}\r\n",
      "{'loss': 0.2098, 'learning_rate': 4.415209238134595e-09, 'epoch': 0.12}\r\n",
      "{'loss': 0.1865, 'learning_rate': 4.395716212739082e-09, 'epoch': 0.12}\r\n",
      "{'loss': 0.2038, 'learning_rate': 4.376223187343569e-09, 'epoch': 0.12}\r\n",
      "{'loss': 0.1956, 'learning_rate': 4.356730161948055e-09, 'epoch': 0.13}\r\n",
      "{'loss': 0.2342, 'learning_rate': 4.337237136552542e-09, 'epoch': 0.13}\r\n",
      "{'loss': 0.2108, 'learning_rate': 4.317744111157028e-09, 'epoch': 0.14}\r\n",
      "{'loss': 0.1784, 'learning_rate': 4.298251085761515e-09, 'epoch': 0.14}\r\n",
      "{'loss': 0.2099, 'learning_rate': 4.278758060366001e-09, 'epoch': 0.14}\r\n",
      "{'loss': 0.2208, 'learning_rate': 4.259265034970488e-09, 'epoch': 0.15}\r\n",
      "{'loss': 0.2212, 'learning_rate': 4.239772009574974e-09, 'epoch': 0.15}\r\n",
      "{'loss': 0.214, 'learning_rate': 4.2202789841794606e-09, 'epoch': 0.16}\r\n",
      "{'loss': 0.186, 'learning_rate': 4.200785958783947e-09, 'epoch': 0.16}\r\n",
      "{'loss': 0.207, 'learning_rate': 4.1812929333884335e-09, 'epoch': 0.16}\r\n",
      "{'loss': 0.2024, 'learning_rate': 4.16179990799292e-09, 'epoch': 0.17}\r\n",
      "{'loss': 0.2288, 'learning_rate': 4.142306882597407e-09, 'epoch': 0.17}\r\n",
      "{'loss': 0.2402, 'learning_rate': 4.122813857201893e-09, 'epoch': 0.18}\r\n",
      "{'loss': 0.237, 'learning_rate': 4.10332083180638e-09, 'epoch': 0.18}\r\n",
      "{'loss': 0.2064, 'learning_rate': 4.0838278064108665e-09, 'epoch': 0.18}\r\n",
      "{'loss': 0.2259, 'learning_rate': 4.064334781015353e-09, 'epoch': 0.19}\r\n",
      "{'loss': 0.214, 'learning_rate': 4.0448417556198394e-09, 'epoch': 0.19}\r\n",
      "{'loss': 0.1839, 'learning_rate': 4.025348730224326e-09, 'epoch': 0.19}\r\n",
      "{'loss': 0.2231, 'learning_rate': 4.005855704828812e-09, 'epoch': 0.2}\r\n",
      "{'loss': 0.2048, 'learning_rate': 3.986362679433299e-09, 'epoch': 0.2}\r\n",
      "{'loss': 0.212, 'learning_rate': 3.966869654037785e-09, 'epoch': 0.21}\r\n",
      "{'loss': 0.2189, 'learning_rate': 3.947376628642272e-09, 'epoch': 0.21}\r\n",
      "{'loss': 0.2317, 'learning_rate': 3.927883603246758e-09, 'epoch': 0.21}\r\n",
      "{'loss': 0.2188, 'learning_rate': 3.908390577851245e-09, 'epoch': 0.22}\r\n",
      "{'loss': 0.2394, 'learning_rate': 3.888897552455731e-09, 'epoch': 0.22}\r\n",
      "{'loss': 0.2647, 'learning_rate': 3.869404527060218e-09, 'epoch': 0.23}\r\n",
      "{'loss': 0.2175, 'learning_rate': 3.849911501664705e-09, 'epoch': 0.23}\r\n",
      "{'loss': 0.2176, 'learning_rate': 3.83041847626919e-09, 'epoch': 0.23}\r\n",
      "{'loss': 0.2225, 'learning_rate': 3.810925450873678e-09, 'epoch': 0.24}\r\n",
      "{'loss': 0.2237, 'learning_rate': 3.791432425478164e-09, 'epoch': 0.24}\r\n",
      "{'loss': 0.2208, 'learning_rate': 3.7719394000826506e-09, 'epoch': 0.25}\r\n",
      "{'loss': 0.2333, 'learning_rate': 3.752446374687137e-09, 'epoch': 0.25}\r\n",
      "{'loss': 0.2165, 'learning_rate': 3.7329533492916235e-09, 'epoch': 0.25}\r\n",
      "{'loss': 0.2331, 'learning_rate': 3.71346032389611e-09, 'epoch': 0.26}\r\n",
      "{'loss': 0.2287, 'learning_rate': 3.6939672985005968e-09, 'epoch': 0.26}\r\n",
      "{'loss': 0.2288, 'learning_rate': 3.674474273105083e-09, 'epoch': 0.27}\r\n",
      "{'loss': 0.2445, 'learning_rate': 3.6549812477095697e-09, 'epoch': 0.27}\r\n",
      "{'loss': 0.2364, 'learning_rate': 3.635488222314056e-09, 'epoch': 0.27}\r\n",
      "{'loss': 0.2326, 'learning_rate': 3.615995196918543e-09, 'epoch': 0.28}\r\n",
      "{'loss': 0.2267, 'learning_rate': 3.596502171523029e-09, 'epoch': 0.28}\r\n",
      "{'loss': 0.2549, 'learning_rate': 3.5770091461275155e-09, 'epoch': 0.28}\r\n",
      "{'loss': 0.2257, 'learning_rate': 3.5575161207320023e-09, 'epoch': 0.29}\r\n",
      "{'loss': 0.2384, 'learning_rate': 3.5380230953364888e-09, 'epoch': 0.29}\r\n",
      "{'loss': 0.2172, 'learning_rate': 3.518530069940975e-09, 'epoch': 0.3}\r\n",
      "{'loss': 0.2054, 'learning_rate': 3.4990370445454617e-09, 'epoch': 0.3}\r\n",
      "{'loss': 0.2376, 'learning_rate': 3.479544019149948e-09, 'epoch': 0.3}\r\n",
      "{'loss': 0.2353, 'learning_rate': 3.460050993754435e-09, 'epoch': 0.31}\r\n",
      "{'loss': 0.2816, 'learning_rate': 3.440557968358921e-09, 'epoch': 0.31}\r\n",
      "{'loss': 0.2149, 'learning_rate': 3.421064942963408e-09, 'epoch': 0.32}\r\n",
      "{'loss': 0.2274, 'learning_rate': 3.4015719175678943e-09, 'epoch': 0.32}\r\n",
      "{'loss': 0.2179, 'learning_rate': 3.3820788921723804e-09, 'epoch': 0.32}\r\n",
      "{'loss': 0.2715, 'learning_rate': 3.3625858667768672e-09, 'epoch': 0.33}\r\n",
      "{'loss': 0.2399, 'learning_rate': 3.3430928413813537e-09, 'epoch': 0.33}\r\n",
      "{'loss': 0.238, 'learning_rate': 3.3235998159858406e-09, 'epoch': 0.34}\r\n",
      "{'loss': 0.2539, 'learning_rate': 3.3041067905903266e-09, 'epoch': 0.34}\r\n",
      "{'loss': 0.2445, 'learning_rate': 3.2846137651948135e-09, 'epoch': 0.34}\r\n",
      "{'loss': 0.226, 'learning_rate': 3.2651207397993e-09, 'epoch': 0.35}\r\n",
      "{'loss': 0.2553, 'learning_rate': 3.2456277144037868e-09, 'epoch': 0.35}\r\n",
      "{'loss': 0.2392, 'learning_rate': 3.226134689008273e-09, 'epoch': 0.35}\r\n",
      "{'loss': 0.2339, 'learning_rate': 3.2066416636127593e-09, 'epoch': 0.36}\r\n",
      "{'loss': 0.2384, 'learning_rate': 3.187148638217246e-09, 'epoch': 0.36}\r\n",
      "{'loss': 0.2705, 'learning_rate': 3.1676556128217326e-09, 'epoch': 0.37}\r\n",
      "{'loss': 0.2596, 'learning_rate': 3.1481625874262186e-09, 'epoch': 0.37}\r\n",
      "{'loss': 0.2628, 'learning_rate': 3.1286695620307055e-09, 'epoch': 0.37}\r\n",
      "{'loss': 0.2287, 'learning_rate': 3.109176536635192e-09, 'epoch': 0.38}\r\n",
      "{'loss': 0.2532, 'learning_rate': 3.0896835112396788e-09, 'epoch': 0.38}\r\n",
      "{'loss': 0.2388, 'learning_rate': 3.070190485844165e-09, 'epoch': 0.39}\r\n",
      "{'loss': 0.2401, 'learning_rate': 3.0506974604486517e-09, 'epoch': 0.39}\r\n",
      "{'loss': 0.2726, 'learning_rate': 3.031204435053138e-09, 'epoch': 0.39}\r\n",
      "{'loss': 0.2812, 'learning_rate': 3.011711409657625e-09, 'epoch': 0.4}\r\n",
      "{'loss': 0.2839, 'learning_rate': 2.992218384262111e-09, 'epoch': 0.4}\r\n",
      "{'loss': 0.2785, 'learning_rate': 2.9727253588665975e-09, 'epoch': 0.41}\r\n",
      "{'loss': 0.2539, 'learning_rate': 2.9532323334710843e-09, 'epoch': 0.41}\r\n",
      "{'loss': 0.223, 'learning_rate': 2.9337393080755708e-09, 'epoch': 0.41}\r\n",
      "{'loss': 0.2536, 'learning_rate': 2.914246282680057e-09, 'epoch': 0.42}\r\n",
      "{'loss': 0.2859, 'learning_rate': 2.8947532572845437e-09, 'epoch': 0.42}\r\n",
      "{'loss': 0.2785, 'learning_rate': 2.87526023188903e-09, 'epoch': 0.42}\r\n",
      "{'loss': 0.2518, 'learning_rate': 2.855767206493517e-09, 'epoch': 0.43}\r\n",
      "{'loss': 0.2568, 'learning_rate': 2.836274181098003e-09, 'epoch': 0.43}\r\n",
      "{'loss': 0.2251, 'learning_rate': 2.81678115570249e-09, 'epoch': 0.44}\r\n",
      "{'loss': 0.2675, 'learning_rate': 2.7972881303069763e-09, 'epoch': 0.44}\r\n",
      "{'loss': 0.2583, 'learning_rate': 2.7777951049114624e-09, 'epoch': 0.44}\r\n",
      "{'loss': 0.2736, 'learning_rate': 2.7583020795159492e-09, 'epoch': 0.45}\r\n",
      "{'loss': 0.2761, 'learning_rate': 2.7388090541204357e-09, 'epoch': 0.45}\r\n",
      "{'loss': 0.2408, 'learning_rate': 2.7193160287249226e-09, 'epoch': 0.46}\r\n",
      "{'loss': 0.2378, 'learning_rate': 2.6998230033294086e-09, 'epoch': 0.46}\r\n",
      "{'loss': 0.3179, 'learning_rate': 2.680329977933895e-09, 'epoch': 0.46}\r\n",
      "{'loss': 0.2656, 'learning_rate': 2.660836952538382e-09, 'epoch': 0.47}\r\n",
      "{'loss': 0.2618, 'learning_rate': 2.6413439271428684e-09, 'epoch': 0.47}\r\n",
      "{'loss': 0.2764, 'learning_rate': 2.621850901747355e-09, 'epoch': 0.48}\r\n",
      "{'loss': 0.3328, 'learning_rate': 2.6023578763518413e-09, 'epoch': 0.48}\r\n",
      "{'loss': 0.2927, 'learning_rate': 2.582864850956328e-09, 'epoch': 0.48}\r\n",
      "{'loss': 0.26, 'learning_rate': 2.5633718255608146e-09, 'epoch': 0.49}\r\n",
      "{'loss': 0.2697, 'learning_rate': 2.5438788001653006e-09, 'epoch': 0.49}\r\n",
      "{'loss': 0.2714, 'learning_rate': 2.5243857747697875e-09, 'epoch': 0.5}\r\n",
      "{'loss': 0.2783, 'learning_rate': 2.504892749374274e-09, 'epoch': 0.5}\r\n",
      "{'loss': 0.3124, 'learning_rate': 2.4853997239787604e-09, 'epoch': 0.5}\r\n",
      "{'loss': 0.2717, 'learning_rate': 2.4659066985832472e-09, 'epoch': 0.51}\r\n",
      "{'loss': 0.2803, 'learning_rate': 2.4464136731877333e-09, 'epoch': 0.51}\r\n",
      "{'loss': 0.2748, 'learning_rate': 2.42692064779222e-09, 'epoch': 0.51}\r\n",
      "{'loss': 0.3062, 'learning_rate': 2.4074276223967066e-09, 'epoch': 0.52}\r\n",
      "{'loss': 0.2913, 'learning_rate': 2.387934597001193e-09, 'epoch': 0.52}\r\n",
      "{'loss': 0.2348, 'learning_rate': 2.3684415716056795e-09, 'epoch': 0.53}\r\n",
      "{'loss': 0.305, 'learning_rate': 2.3489485462101663e-09, 'epoch': 0.53}\r\n",
      "{'loss': 0.2438, 'learning_rate': 2.3294555208146524e-09, 'epoch': 0.53}\r\n",
      "{'loss': 0.275, 'learning_rate': 2.309962495419139e-09, 'epoch': 0.54}\r\n",
      "{'loss': 0.2446, 'learning_rate': 2.2904694700236257e-09, 'epoch': 0.54}\r\n",
      "{'loss': 0.2697, 'learning_rate': 2.270976444628112e-09, 'epoch': 0.55}\r\n",
      "{'loss': 0.2874, 'learning_rate': 2.2514834192325986e-09, 'epoch': 0.55}\r\n",
      "{'loss': 0.303, 'learning_rate': 2.231990393837085e-09, 'epoch': 0.55}\r\n",
      "{'loss': 0.2918, 'learning_rate': 2.2124973684415715e-09, 'epoch': 0.56}\r\n",
      "{'loss': 0.2689, 'learning_rate': 2.193004343046058e-09, 'epoch': 0.56}\r\n",
      "{'loss': 0.3046, 'learning_rate': 2.173511317650545e-09, 'epoch': 0.57}\r\n",
      "{'loss': 0.2806, 'learning_rate': 2.1540182922550313e-09, 'epoch': 0.57}\r\n",
      "{'loss': 0.2903, 'learning_rate': 2.1345252668595177e-09, 'epoch': 0.57}\r\n",
      "{'loss': 0.3076, 'learning_rate': 2.115032241464004e-09, 'epoch': 0.58}\r\n",
      "{'loss': 0.3237, 'learning_rate': 2.0955392160684906e-09, 'epoch': 0.58}\r\n",
      "{'loss': 0.3213, 'learning_rate': 2.076046190672977e-09, 'epoch': 0.58}\r\n",
      "{'loss': 0.2655, 'learning_rate': 2.056553165277464e-09, 'epoch': 0.59}\r\n",
      "{'loss': 0.2714, 'learning_rate': 2.0370601398819504e-09, 'epoch': 0.59}\r\n",
      "{'loss': 0.2744, 'learning_rate': 2.017567114486437e-09, 'epoch': 0.6}\r\n",
      "{'loss': 0.3177, 'learning_rate': 1.9980740890909233e-09, 'epoch': 0.6}\r\n",
      "{'loss': 0.2684, 'learning_rate': 1.9785810636954097e-09, 'epoch': 0.6}\r\n",
      "{'loss': 0.2784, 'learning_rate': 1.959088038299896e-09, 'epoch': 0.61}\r\n",
      "{'loss': 0.3264, 'learning_rate': 1.939595012904383e-09, 'epoch': 0.61}\r\n",
      "{'loss': 0.2875, 'learning_rate': 1.9201019875088695e-09, 'epoch': 0.62}\r\n",
      "{'loss': 0.2983, 'learning_rate': 1.900608962113356e-09, 'epoch': 0.62}\r\n",
      "{'loss': 0.3077, 'learning_rate': 1.8811159367178424e-09, 'epoch': 0.62}\r\n",
      "{'loss': 0.3104, 'learning_rate': 1.861622911322329e-09, 'epoch': 0.63}\r\n",
      "{'loss': 0.2949, 'learning_rate': 1.8421298859268155e-09, 'epoch': 0.63}\r\n",
      "{'loss': 0.3264, 'learning_rate': 1.8226368605313021e-09, 'epoch': 0.64}\r\n",
      "{'loss': 0.3087, 'learning_rate': 1.8031438351357884e-09, 'epoch': 0.64}\r\n",
      "{'loss': 0.317, 'learning_rate': 1.783650809740275e-09, 'epoch': 0.64}\r\n",
      "{'loss': 0.3358, 'learning_rate': 1.7641577843447615e-09, 'epoch': 0.65}\r\n",
      "{'loss': 0.3138, 'learning_rate': 1.744664758949248e-09, 'epoch': 0.65}\r\n",
      "{'loss': 0.3417, 'learning_rate': 1.7251717335537346e-09, 'epoch': 0.65}\r\n",
      "{'loss': 0.3434, 'learning_rate': 1.7056787081582208e-09, 'epoch': 0.66}\r\n",
      "{'loss': 0.3199, 'learning_rate': 1.6861856827627075e-09, 'epoch': 0.66}\r\n",
      "{'loss': 0.3039, 'learning_rate': 1.666692657367194e-09, 'epoch': 0.67}\r\n",
      "{'loss': 0.3479, 'learning_rate': 1.6471996319716806e-09, 'epoch': 0.67}\r\n",
      "{'loss': 0.3188, 'learning_rate': 1.627706606576167e-09, 'epoch': 0.67}\r\n",
      "{'loss': 0.3326, 'learning_rate': 1.6082135811806537e-09, 'epoch': 0.68}\r\n",
      "{'loss': 0.3385, 'learning_rate': 1.58872055578514e-09, 'epoch': 0.68}\r\n",
      "{'loss': 0.3265, 'learning_rate': 1.5692275303896266e-09, 'epoch': 0.69}\r\n",
      "{'loss': 0.3547, 'learning_rate': 1.549734504994113e-09, 'epoch': 0.69}\r\n",
      "{'loss': 0.3381, 'learning_rate': 1.5302414795985997e-09, 'epoch': 0.69}\r\n",
      "{'loss': 0.3126, 'learning_rate': 1.5107484542030862e-09, 'epoch': 0.7}\r\n",
      "{'loss': 0.3122, 'learning_rate': 1.4912554288075728e-09, 'epoch': 0.7}\r\n",
      "{'loss': 0.3524, 'learning_rate': 1.471762403412059e-09, 'epoch': 0.71}\r\n",
      "{'loss': 0.3509, 'learning_rate': 1.4522693780165457e-09, 'epoch': 0.71}\r\n",
      "{'loss': 0.2933, 'learning_rate': 1.4327763526210322e-09, 'epoch': 0.71}\r\n",
      "{'loss': 0.3535, 'learning_rate': 1.4132833272255188e-09, 'epoch': 0.72}\r\n",
      "{'loss': 0.332, 'learning_rate': 1.3937903018300053e-09, 'epoch': 0.72}\r\n",
      "{'loss': 0.3772, 'learning_rate': 1.374297276434492e-09, 'epoch': 0.73}\r\n",
      "{'loss': 0.3106, 'learning_rate': 1.3548042510389782e-09, 'epoch': 0.73}\r\n",
      "{'loss': 0.3552, 'learning_rate': 1.3353112256434648e-09, 'epoch': 0.73}\r\n",
      "{'loss': 0.3612, 'learning_rate': 1.3158182002479513e-09, 'epoch': 0.74}\r\n",
      "{'loss': 0.361, 'learning_rate': 1.296325174852438e-09, 'epoch': 0.74}\r\n",
      "{'loss': 0.3754, 'learning_rate': 1.2768321494569244e-09, 'epoch': 0.74}\r\n",
      "{'loss': 0.349, 'learning_rate': 1.257339124061411e-09, 'epoch': 0.75}\r\n",
      "{'loss': 0.3661, 'learning_rate': 1.2378460986658973e-09, 'epoch': 0.75}\r\n",
      "{'loss': 0.3301, 'learning_rate': 1.218353073270384e-09, 'epoch': 0.76}\r\n",
      "{'loss': 0.3274, 'learning_rate': 1.1988600478748704e-09, 'epoch': 0.76}\r\n",
      "{'loss': 0.3408, 'learning_rate': 1.1793670224793568e-09, 'epoch': 0.76}\r\n",
      "{'loss': 0.35, 'learning_rate': 1.1598739970838435e-09, 'epoch': 0.77}\r\n",
      "{'loss': 0.3397, 'learning_rate': 1.14038097168833e-09, 'epoch': 0.77}\r\n",
      "{'loss': 0.3566, 'learning_rate': 1.1208879462928164e-09, 'epoch': 0.78}\r\n",
      "{'loss': 0.3445, 'learning_rate': 1.101394920897303e-09, 'epoch': 0.78}\r\n",
      "{'loss': 0.35, 'learning_rate': 1.0819018955017895e-09, 'epoch': 0.78}\r\n",
      "{'loss': 0.4209, 'learning_rate': 1.062408870106276e-09, 'epoch': 0.79}\r\n",
      "{'loss': 0.352, 'learning_rate': 1.0429158447107626e-09, 'epoch': 0.79}\r\n",
      "{'loss': 0.3508, 'learning_rate': 1.023422819315249e-09, 'epoch': 0.8}\r\n",
      "{'loss': 0.367, 'learning_rate': 1.0039297939197355e-09, 'epoch': 0.8}\r\n",
      "{'loss': 0.3214, 'learning_rate': 9.844367685242222e-10, 'epoch': 0.8}\r\n",
      "{'loss': 0.4139, 'learning_rate': 9.649437431287084e-10, 'epoch': 0.81}\r\n",
      "{'loss': 0.4154, 'learning_rate': 9.45450717733195e-10, 'epoch': 0.81}\r\n",
      "{'loss': 0.3937, 'learning_rate': 9.259576923376815e-10, 'epoch': 0.81}\r\n",
      "{'loss': 0.3829, 'learning_rate': 9.064646669421681e-10, 'epoch': 0.82}\r\n",
      "{'loss': 0.4077, 'learning_rate': 8.869716415466546e-10, 'epoch': 0.82}\r\n",
      "{'loss': 0.3998, 'learning_rate': 8.674786161511411e-10, 'epoch': 0.83}\r\n",
      "{'loss': 0.3943, 'learning_rate': 8.479855907556276e-10, 'epoch': 0.83}\r\n",
      "{'loss': 0.4045, 'learning_rate': 8.284925653601142e-10, 'epoch': 0.83}\r\n",
      "{'loss': 0.3862, 'learning_rate': 8.089995399646006e-10, 'epoch': 0.84}\r\n",
      "{'loss': 0.412, 'learning_rate': 7.895065145690872e-10, 'epoch': 0.84}\r\n",
      "{'loss': 0.3771, 'learning_rate': 7.700134891735737e-10, 'epoch': 0.85}\r\n",
      "{'loss': 0.4167, 'learning_rate': 7.505204637780602e-10, 'epoch': 0.85}\r\n",
      "{'loss': 0.4106, 'learning_rate': 7.310274383825467e-10, 'epoch': 0.85}\r\n",
      "{'loss': 0.397, 'learning_rate': 7.115344129870333e-10, 'epoch': 0.86}\r\n",
      "{'loss': 0.4691, 'learning_rate': 6.920413875915197e-10, 'epoch': 0.86}\r\n",
      "{'loss': 0.3739, 'learning_rate': 6.725483621960063e-10, 'epoch': 0.87}\r\n",
      "{'loss': 0.4132, 'learning_rate': 6.530553368004928e-10, 'epoch': 0.87}\r\n",
      "{'loss': 0.4288, 'learning_rate': 6.335623114049793e-10, 'epoch': 0.87}\r\n",
      "{'loss': 0.4163, 'learning_rate': 6.140692860094658e-10, 'epoch': 0.88}\r\n",
      "{'loss': 0.42, 'learning_rate': 5.945762606139524e-10, 'epoch': 0.88}\r\n",
      "{'loss': 0.385, 'learning_rate': 5.750832352184388e-10, 'epoch': 0.88}\r\n",
      "{'loss': 0.4143, 'learning_rate': 5.555902098229253e-10, 'epoch': 0.89}\r\n",
      "{'loss': 0.4278, 'learning_rate': 5.360971844274118e-10, 'epoch': 0.89}\r\n",
      "{'loss': 0.4246, 'learning_rate': 5.166041590318984e-10, 'epoch': 0.9}\r\n",
      "{'loss': 0.3953, 'learning_rate': 4.971111336363849e-10, 'epoch': 0.9}\r\n",
      "{'loss': 0.4445, 'learning_rate': 4.776181082408714e-10, 'epoch': 0.9}\r\n",
      "{'loss': 0.4762, 'learning_rate': 4.5812508284535795e-10, 'epoch': 0.91}\r\n",
      "{'loss': 0.4532, 'learning_rate': 4.3863205744984445e-10, 'epoch': 0.91}\r\n",
      "{'loss': 0.4305, 'learning_rate': 4.1913903205433095e-10, 'epoch': 0.92}\r\n",
      "{'loss': 0.4409, 'learning_rate': 3.996460066588175e-10, 'epoch': 0.92}\r\n",
      "{'loss': 0.4072, 'learning_rate': 3.80152981263304e-10, 'epoch': 0.92}\r\n",
      "{'loss': 0.4522, 'learning_rate': 3.606599558677905e-10, 'epoch': 0.93}\r\n",
      "{'loss': 0.4486, 'learning_rate': 3.4116693047227706e-10, 'epoch': 0.93}\r\n",
      "{'loss': 0.4282, 'learning_rate': 3.2167390507676356e-10, 'epoch': 0.94}\r\n",
      "{'loss': 0.442, 'learning_rate': 3.0218087968125006e-10, 'epoch': 0.94}\r\n",
      "{'loss': 0.4505, 'learning_rate': 2.8268785428573656e-10, 'epoch': 0.94}\r\n",
      "{'loss': 0.4567, 'learning_rate': 2.631948288902231e-10, 'epoch': 0.95}\r\n",
      "{'loss': 0.443, 'learning_rate': 2.437018034947096e-10, 'epoch': 0.95}\r\n",
      "{'loss': 0.4757, 'learning_rate': 2.242087780991961e-10, 'epoch': 0.96}\r\n",
      "{'loss': 0.4914, 'learning_rate': 2.0471575270368262e-10, 'epoch': 0.96}\r\n",
      "{'loss': 0.453, 'learning_rate': 1.8522272730816915e-10, 'epoch': 0.96}\r\n",
      "{'loss': 0.4738, 'learning_rate': 1.6572970191265565e-10, 'epoch': 0.97}\r\n",
      "{'loss': 0.4828, 'learning_rate': 1.4623667651714218e-10, 'epoch': 0.97}\r\n",
      "{'loss': 0.5021, 'learning_rate': 1.2674365112162868e-10, 'epoch': 0.97}\r\n",
      "{'loss': 0.419, 'learning_rate': 1.0725062572611519e-10, 'epoch': 0.98}\r\n",
      "{'loss': 0.5548, 'learning_rate': 8.775760033060172e-11, 'epoch': 0.98}\r\n",
      "{'loss': 0.4679, 'learning_rate': 6.826457493508823e-11, 'epoch': 0.99}\r\n",
      "{'loss': 0.4855, 'learning_rate': 4.877154953957474e-11, 'epoch': 0.99}\r\n",
      "{'loss': 0.484, 'learning_rate': 2.9278524144061254e-11, 'epoch': 0.99}\r\n",
      "{'loss': 0.5381, 'learning_rate': 9.78549874854777e-12, 'epoch': 1.0}\r\n",
      "100%|| 128000/128251 [5:51:10<00:39,  6.36it/s][INFO|trainer.py:1408] 2021-02-17 09:57:33,565 >> Saving model checkpoint to /kaggle/working/checkpoint-128000\r\n",
      "[INFO|configuration_utils.py:304] 2021-02-17 09:57:33,569 >> Configuration saved in /kaggle/working/checkpoint-128000/config.json\r\n",
      "[INFO|modeling_utils.py:817] 2021-02-17 09:57:36,053 >> Model weights saved in /kaggle/working/checkpoint-128000/pytorch_model.bin\r\n",
      "100%|| 128251/128251 [5:52:13<00:00,  3.04it/s][INFO|trainer.py:1007] 2021-02-17 09:58:37,071 >> \r\n",
      "\r\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\r\n",
      "\r\n",
      "\r\n",
      "{'train_runtime': 21133.5369, 'train_samples_per_second': 6.069, 'epoch': 1.0}\r\n",
      "100%|| 128251/128251 [5:52:13<00:00,  6.07it/s]\r\n",
      "[INFO|trainer.py:1408] 2021-02-17 09:58:37,074 >> Saving model checkpoint to /kaggle/working\r\n",
      "[INFO|configuration_utils.py:304] 2021-02-17 09:58:37,081 >> Configuration saved in /kaggle/working/config.json\r\n",
      "[INFO|modeling_utils.py:817] 2021-02-17 09:58:40,869 >> Model weights saved in /kaggle/working/pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/working/transformers/examples/seq2seq/finetune_trainer.py --model_name_or_path /kaggle/input/bartb5/ --tokenizer_name /kaggle/input/bartb5/  --data_dir /kaggle/working --task summarization --output_dir /kaggle/working --per_device_train_batch_size 1 --learning_rate 0.000000005 --overwrite_output_dir --save_steps 128000 --num_train_epochs 1 --do_train  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2021-02-17T10:00:24.551284Z",
     "iopub.status.busy": "2021-02-17T10:00:24.550437Z",
     "iopub.status.idle": "2021-02-17T10:06:45.469402Z",
     "shell.execute_reply": "2021-02-17T10:06:45.468293Z"
    },
    "papermill": {
     "duration": 419.400071,
     "end_time": "2021-02-17T10:06:45.469548",
     "exception": false,
     "start_time": "2021-02-17T09:59:46.069477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/106 [00:00<?, ?it/s]2021-02-17 10:00:50.517078: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "100%|| 106/106 [05:50<00:00,  3.31s/it]\r\n",
      "{'rouge1': 55.3159, 'rouge2': 39.0386, 'rougeL': 51.1177, 'rougeLsum': 51.1649, 'n_obs': 3377, 'runtime': 350, 'seconds_per_sample': 0.1036}\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/working/transformers/examples/seq2seq/run_eval.py /kaggle/working/ /kaggle/working/val.source /kaggle/working/val.csv --reference_path /kaggle/working/val.target --score_path /kaggle/working/rouge.json --task summarization --device cuda --bs 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T10:08:01.658482Z",
     "iopub.status.busy": "2021-02-17T10:08:01.653020Z",
     "iopub.status.idle": "2021-02-17T10:08:05.838434Z",
     "shell.execute_reply": "2021-02-17T10:08:05.840249Z"
    },
    "papermill": {
     "duration": 42.145962,
     "end_time": "2021-02-17T10:08:05.840463",
     "exception": false,
     "start_time": "2021-02-17T10:07:23.694501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/transformers/examples/seq2seq/run_eval.py:136: UserWarning: score_path /kaggle/working/rouge.json will be overwritten unless you type ctrl-c.\r\n",
      "  warnings.warn(f\"score_path {args.score_path} will be overwritten unless you type ctrl-c.\")\r\n",
      "file /kaggle/input/bart-seq2seq-finetune/config.json not found\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/transformers/src/transformers/configuration_utils.py\", line 424, in get_config_dict\r\n",
      "    use_auth_token=use_auth_token,\r\n",
      "  File \"/kaggle/working/transformers/src/transformers/file_utils.py\", line 1093, in cached_path\r\n",
      "    raise EnvironmentError(\"file {} not found\".format(url_or_filename))\r\n",
      "OSError: file /kaggle/input/bart-seq2seq-finetune/config.json not found\r\n",
      "\r\n",
      "During handling of the above exception, another exception occurred:\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/transformers/examples/seq2seq/run_eval.py\", line 176, in <module>\r\n",
      "    run_generate(verbose=True)\r\n",
      "  File \"/kaggle/working/transformers/examples/seq2seq/run_eval.py\", line 146, in run_generate\r\n",
      "    **parsed_args,\r\n",
      "  File \"/kaggle/working/transformers/examples/seq2seq/run_eval.py\", line 52, in generate_summaries_or_translations\r\n",
      "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\r\n",
      "  File \"/kaggle/working/transformers/src/transformers/models/auto/modeling_auto.py\", line 1257, in from_pretrained\r\n",
      "    pretrained_model_name_or_path, return_unused_kwargs=True, **kwargs\r\n",
      "  File \"/kaggle/working/transformers/src/transformers/models/auto/configuration_auto.py\", line 368, in from_pretrained\r\n",
      "    config_dict, _ = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\r\n",
      "  File \"/kaggle/working/transformers/src/transformers/configuration_utils.py\", line 436, in get_config_dict\r\n",
      "    raise EnvironmentError(msg)\r\n",
      "OSError: Can't load config for '/kaggle/input/bart-seq2seq-finetune/'. Make sure that:\r\n",
      "\r\n",
      "- '/kaggle/input/bart-seq2seq-finetune/' is a correct model identifier listed on 'https://huggingface.co/models'\r\n",
      "\r\n",
      "- or '/kaggle/input/bart-seq2seq-finetune/' is the correct path to a directory containing a config.json file\r\n",
      "\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python3 /kaggle/working/transformers/examples/seq2seq/run_eval.py /kaggle/input/bart-seq2seq-finetune/ /kaggle/working/testN.txt /kaggle/working/test_resN.csv --score_path /kaggle/working/rouge.json --task summarization --device cuda --bs 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T10:09:22.278096Z",
     "iopub.status.busy": "2021-02-17T10:09:22.277571Z",
     "iopub.status.idle": "2021-02-17T10:09:22.367112Z",
     "shell.execute_reply": "2021-02-17T10:09:22.368458Z"
    },
    "papermill": {
     "duration": 38.612332,
     "end_time": "2021-02-17T10:09:22.368631",
     "exception": false,
     "start_time": "2021-02-17T10:08:43.756299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2785\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2786\u001b[0;31m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffered_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_buffered_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2860\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2861\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_line\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2957\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m                 \u001b[0morig_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_iter_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_next_iter_line\u001b[0;34m(self, row_num)\u001b[0m\n\u001b[1;32m   3015\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3016\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3017\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9f08d21aa0dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/working/test_resN.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                     \u001b[0;34m'are \"c\", \"python\", or \"python-fwf\")'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 )\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2405\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_original_columns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2406\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2407\u001b[0;31m             ) = self._infer_columns()\n\u001b[0m\u001b[1;32m   2408\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_infer_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2788\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmptyDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No columns to parse from file\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "titles = pd.read_csv(\"/kaggle/working/test_resN.csv\", engine='python', encoding='utf-8', error_bad_lines=False, header=None)\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T10:10:38.588459Z",
     "iopub.status.busy": "2021-02-17T10:10:38.587717Z",
     "iopub.status.idle": "2021-02-17T10:10:38.590981Z",
     "shell.execute_reply": "2021-02-17T10:10:38.591430Z"
    },
    "papermill": {
     "duration": 38.17126,
     "end_time": "2021-02-17T10:10:38.591550",
     "exception": false,
     "start_time": "2021-02-17T10:10:00.420290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"/kaggle/working/test_resN.csv\", 'r')\n",
    "titles = [line.strip() for line in f]\n",
    "f.close()\n",
    "\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T10:11:55.104059Z",
     "iopub.status.busy": "2021-02-17T10:11:55.103472Z",
     "iopub.status.idle": "2021-02-17T10:11:55.122032Z",
     "shell.execute_reply": "2021-02-17T10:11:55.121473Z"
    },
    "papermill": {
     "duration": 38.357953,
     "end_time": "2021-02-17T10:11:55.122126",
     "exception": false,
     "start_time": "2021-02-17T10:11:16.764173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-1e67d7695413>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'abstract'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mabstracts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtitles\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./predicted_titles.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'abstract': abstracts, 'title': titles})\n",
    "submission_df.to_csv('./predicted_titles.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-17T10:13:12.227004Z",
     "iopub.status.busy": "2021-02-17T10:13:12.226107Z",
     "iopub.status.idle": "2021-02-17T10:13:12.866729Z",
     "shell.execute_reply": "2021-02-17T10:13:12.867306Z"
    },
    "papermill": {
     "duration": 39.649964,
     "end_time": "2021-02-17T10:13:12.867443",
     "exception": false,
     "start_time": "2021-02-17T10:12:33.217479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/working/predicted_titles.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-91620e4716aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mgenerate_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-91620e4716aa>\u001b[0m in \u001b[0;36mgenerate_csv\u001b[0;34m(input_file, output_file, voc_file)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mvoc_file\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpkl\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     '''\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mvoc_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mvocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/working/predicted_titles.csv'"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from nltk.util import ngrams\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "def generate_csv(input_file='/kaggle/working/predicted_titles.csv',\n",
    "                 output_file='/kaggle/working/submission.csv',\n",
    "                 voc_file='/kaggle/input/arxiv-title-generation/vocs.pkl'):\n",
    "    '''\n",
    "    Generates file in format required for submitting result to Kaggle\n",
    "    \n",
    "    Parameters:\n",
    "        input_file (str) : path to csv file with your predicted titles.\n",
    "                           Should have two fields: abstract and title\n",
    "        output_file (str) : path to output submission file\n",
    "        voc_file (str) : path to voc.pkl file\n",
    "    '''\n",
    "    data = pd.read_csv(input_file)\n",
    "    with open(voc_file, 'rb') as voc_file:\n",
    "        vocs = pickle.load(voc_file)\n",
    "\n",
    "    with open(output_file, 'w') as res_file:\n",
    "        res_file.write('Id,Predict\\n')\n",
    "        \n",
    "    output_idx = 0\n",
    "    for row_idx, row in data.iterrows():\n",
    "        trg = row['title']\n",
    "        trg = trg.translate(str.maketrans('', '', string.punctuation)).lower().split()\n",
    "        trg.extend(['_'.join(ngram) for ngram in list(ngrams(trg, 2)) + list(ngrams(trg, 3))])\n",
    "        \n",
    "        VOCAB_stoi = vocs[row_idx]\n",
    "        trg_intersection = set(VOCAB_stoi.keys()).intersection(set(trg))\n",
    "        trg_vec = np.zeros(len(VOCAB_stoi))    \n",
    "\n",
    "        for word in trg_intersection:\n",
    "            trg_vec[VOCAB_stoi[word]] = 1\n",
    "\n",
    "        with open(output_file, 'a') as res_file:\n",
    "            for is_word in trg_vec:\n",
    "                res_file.write('{0},{1}\\n'.format(output_idx, int(is_word)))\n",
    "                output_idx += 1\n",
    "\n",
    "\n",
    "generate_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 22184.26321,
   "end_time": "2021-02-17T10:13:53.067084",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-17T04:04:08.803874",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
