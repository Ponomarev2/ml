{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2197a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94be7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[1,2,3], [0,0,0], [1,1,1], [9,6,3], [3,4,5],\n",
    "           [2,2,1], [0,0,0], [1,1,1], [9,6,3], [3,4,5],\n",
    "           [1,2,3], [0,0,0], [1,1,1], [9,6,3], [3,4,5],]\n",
    "y_train = [1,2,3,4,5,\n",
    "           6,7,8,9,10,\n",
    "           1,2,3,4,5,]\n",
    "X_test = [list(range(i,i+3)) for i in range(10,12)]\n",
    "y_test = [i+3 for i in range(10,12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a208de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X)\n",
    "        self.y = torch.Tensor(y).unsqueeze(1)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd17cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 1\n",
    "dataset_train = Dataset(X_train, y_train)\n",
    "dataset_test = Dataset(X_test, y_test)\n",
    "train_dl = torch.utils.data.DataLoader(dataset_train, batch_size=batchSize, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(dataset_test, batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cd9cbcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElmanRNN(torch.nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(ElmanRNN, self).__init__()\n",
    "        self.hidden_size = 10\n",
    "        self.W_x = Linear(n_inputs, self.hidden_size)\n",
    "        self.W_h = Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W_o = Linear(self.hidden_size, 1)\n",
    "        self.activation = LeakyReLU()\n",
    "\n",
    " \n",
    "    def forward(self, X, h):\n",
    "        X = self.W_x(X)\n",
    "        h = self.W_h(h)\n",
    "        h = self.activation(X + h)\n",
    "        X = self.W_o(h)\n",
    "        return X, h\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fbab4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0 = ElmanRNN(len(X_train[0])).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d938a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = MSELoss()   \n",
    "optimizer = torch.optim.Adam(model_0.parameters(), lr=1e-4, weight_decay=1e-7)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, min_lr=1e-6, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "456f3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model_0.init_hidden().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2458503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.]], device='cuda:0') tensor([[1.]], device='cuda:0')\n",
      "tensor([[1.0834]], device='cuda:0')\n",
      "tensor([[0., 0., 0.]], device='cuda:0') tensor([[2.]], device='cuda:0')\n",
      "tensor([[1.7234]], device='cuda:0')\n",
      "tensor([[1., 1., 1.]], device='cuda:0') tensor([[3.]], device='cuda:0')\n",
      "tensor([[2.9830]], device='cuda:0')\n",
      "tensor([[9., 6., 3.]], device='cuda:0') tensor([[4.]], device='cuda:0')\n",
      "tensor([[3.7663]], device='cuda:0')\n",
      "tensor([[3., 4., 5.]], device='cuda:0') tensor([[5.]], device='cuda:0')\n",
      "tensor([[4.6752]], device='cuda:0')\n",
      "tensor([[2., 2., 1.]], device='cuda:0') tensor([[6.]], device='cuda:0')\n",
      "tensor([[5.8460]], device='cuda:0')\n",
      "tensor([[0., 0., 0.]], device='cuda:0') tensor([[7.]], device='cuda:0')\n",
      "tensor([[7.6912]], device='cuda:0')\n",
      "tensor([[1., 1., 1.]], device='cuda:0') tensor([[8.]], device='cuda:0')\n",
      "tensor([[6.8943]], device='cuda:0')\n",
      "tensor([[9., 6., 3.]], device='cuda:0') tensor([[9.]], device='cuda:0')\n",
      "tensor([[9.0445]], device='cuda:0')\n",
      "tensor([[3., 4., 5.]], device='cuda:0') tensor([[10.]], device='cuda:0')\n",
      "tensor([[10.0290]], device='cuda:0')\n",
      "tensor([[1., 2., 3.]], device='cuda:0') tensor([[1.]], device='cuda:0')\n",
      "tensor([[1.5970]], device='cuda:0')\n",
      "tensor([[0., 0., 0.]], device='cuda:0') tensor([[2.]], device='cuda:0')\n",
      "tensor([[1.9519]], device='cuda:0')\n",
      "tensor([[1., 1., 1.]], device='cuda:0') tensor([[3.]], device='cuda:0')\n",
      "tensor([[3.0960]], device='cuda:0')\n",
      "tensor([[9., 6., 3.]], device='cuda:0') tensor([[4.]], device='cuda:0')\n",
      "tensor([[4.2036]], device='cuda:0')\n",
      "tensor([[3., 4., 5.]], device='cuda:0') tensor([[5.]], device='cuda:0')\n",
      "tensor([[5.2643]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "model_0.train()\n",
    "for epoch in range(301):\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        yhat, h = model_0(inputs, h)\n",
    "        loss = criterion(yhat, targets)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        h = h.detach()\n",
    "        \n",
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        yhat, h = model_0(inputs, h)\n",
    "        loss = criterion(yhat, targets)\n",
    "        print(inputs, targets)\n",
    "        print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor([[1,2,3]]).to(device)\n",
    "y = torch.Tensor([[4]]).to(device)\n",
    "for j in range(1):\n",
    "    optimizer.zero_grad()\n",
    "    yhat, h = model(x, h)\n",
    "    criterion(y, yhat).backward()\n",
    "    optimizer.step()\n",
    "    h = h.detach()\n",
    "    \n",
    "h, yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d505df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(101):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        yhat, h = model(inputs, h)\n",
    "        loss = criterion(yhat, targets)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(test_dl):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            yhat, h = model(inputs, h)\n",
    "            loss = criterion(yhat, targets)\n",
    "            eval_loss += loss\n",
    "        \n",
    "    #scheduler.step(eval_loss)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: \" + str(epoch) + \", train loss: \" + str(train_loss/len(train_dl)) + \", eval loss: \" + str(eval_loss/len(test_dl)))\n",
    "\n",
    "print(datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db42fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        print(inputs, targets)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        yhat = model(inputs)\n",
    "        print(yhat)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda87e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6f9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
