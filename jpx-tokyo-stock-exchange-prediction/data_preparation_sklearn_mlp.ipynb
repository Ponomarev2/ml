{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c56af2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn import neighbors\n",
    "from sklearn import ensemble\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74bb8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "def calc_spread_return_per_day(df, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    assert df['Rank'].min() == 0\n",
    "    assert df['Rank'].max() == len(df['Rank']) - 1\n",
    "    weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n",
    "    purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n",
    "    return purchase - short\n",
    "\n",
    "def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size=200, toprank_weight_ratio=2):\n",
    "    buf = df.groupby('Date').apply(calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n",
    "    sharpe_ratio = buf.mean() / buf.std()\n",
    "    return sharpe_ratio, buf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3d8ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        df[col] = df[col] * df['AdjustmentFactor']\n",
    "    \n",
    "    df.ExpectedDividend.fillna(0, inplace=True)\n",
    "    df.drop(['AdjustmentFactor', 'RowId'], axis=1, inplace=True)\n",
    "    df['SupervisionFlag'] = df['SupervisionFlag'].astype(int)\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Week'] = df['Date'].dt.week\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    \n",
    "    \n",
    "    df.sort_values(by=['SecuritiesCode','Date'], inplace=True)\n",
    "    df['Open'].interpolate(inplace=True)\n",
    "    df['High'].interpolate(inplace=True)\n",
    "    df['Low'].interpolate(inplace=True)\n",
    "    df['Close'].interpolate(inplace=True)\n",
    "    df.loc[df['Volume'] == 0,\"Volume\"] = np.nan\n",
    "    df['Volume'].interpolate(inplace=True)\n",
    "    df['Target'].interpolate(inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_diffs(df):\n",
    "    d1 = lambda df,col: df[col].diff(periods=1)/(df[col] + 1e-8)\n",
    "\n",
    "    for f in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
    "        df['diff' + f] = d1(df, f)\n",
    "    df['pctDailyChange'] = (df['Close'] - df['Open'])/df['Close']\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "t = pd.read_csv(\"../jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\",\n",
    "                parse_dates=[\"Date\"])\n",
    "t = prepare_data(t)\n",
    "t = create_diffs(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e2230f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes = t.SecuritiesCode.unique()\n",
    "# new_codes = dict(zip(codes, np.arange(2000)))\n",
    "# t = t.replace({'SecuritiesCode' : new_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c55384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = t.loc[t['SecuritiesCode'] == 1376].reset_index(drop=True).copy()\n",
    "stock = create_diffs(stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29f535c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1, ax1 = plt.subplots(figsize=(50, 20), dpi=30)\n",
    "# ax1.plot(stock['Close'][-200:],color='green') \n",
    "# ax1.plot(stock['High'][-200:], color='red') \n",
    "# ax1.plot(stock['Low'][-200:], color='black') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c18df6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    std = x.std()\n",
    "    mean = x.mean()\n",
    "    x = (x - mean) / std\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e374d666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features:\n",
    "#     stock[f] = normalize(stock[f].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72950982",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['diffOpen', 'diffHigh', 'diffLow', 'diffClose', 'diffVolume', 'pctDailyChange',\n",
    "            'ExpectedDividend',]\n",
    "\n",
    "ohlc = ['Open', 'High', 'Low', 'Close']\n",
    "target = 'Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdf0c9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = t.loc[t.Date < t.Date.unique()[100], [*features, target]]\n",
    "# test_df = t.loc[t.Date == t.Date.unique()[100], [*features, target]]\n",
    "# X_train = train_df[features].to_numpy()\n",
    "# y_train = train_df[target].to_numpy()\n",
    "# X_test = test_df[features].to_numpy()\n",
    "# y_test = test_df[target].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9c345ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "X_train, y_train = [], []\n",
    "history_size = 1 # training history\n",
    "val_size = 100\n",
    "\n",
    "for i in range(0, len(stock) - history_size - val_size):\n",
    "    tmp = []\n",
    "    for j in range(history_size):\n",
    "        for f in features:\n",
    "            tmp.append(stock[f].iloc[i+j])\n",
    "    X_train.append(tmp)\n",
    "    y_train.append(stock[target].iloc[i+history_size - 1])\n",
    "\n",
    "X_test, y_test = [], []\n",
    "for i in range(len(stock) - history_size - val_size, len(stock) - history_size):\n",
    "    tmp = []\n",
    "    for j in range(history_size):\n",
    "        for f in features:\n",
    "            tmp.append(stock[f].iloc[i+j])\n",
    "    X_test.append(tmp)\n",
    "    y_test.append(stock[target].iloc[i+history_size - 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b593dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "              \n",
    "# lgbm_regr = LGBMRegressor(boosting_type='goss',objective='regression',\n",
    "#                           metrics='rmse',learning_rate=0.00001, n_estimators=20,\n",
    "#                           max_depth=10)\n",
    "# lgbm_regr.fit(X_train,y_train)\n",
    "# y_pred = lgbm_regr.predict(X_test)\n",
    "# mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f58782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009605654182638292\n",
      "0.009023391928445427\n",
      "0.00881786668843058\n",
      "0.008987550158280283\n",
      "0.008677553812301899\n",
      "0.008819805640479985\n",
      "0.008723310371747848\n",
      "0.009253691990052043\n",
      "0.009019259291144376\n",
      "0.009344389447640055\n",
      "0.008677553812301899\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = []\n",
    "errors = [] \n",
    "for i in range(10):\n",
    "    regr = MLPRegressor(activation='identity', solver='adam', alpha=1e-3, tol=1e-5, max_iter=400, #random_state=i,\n",
    "                         hidden_layer_sizes= tuple([50]*1)).fit(X_train, y_train)\n",
    "\n",
    "    #y_pred = np.array([np.array(y_train).mean()] * len(y_test))\n",
    "    #y_pred = np.zeros(len(y_test)) \n",
    "    y_pred = regr.predict(X_test)\n",
    "    error = mean_absolute_error(y_test, y_pred)\n",
    "    errors.append(error)\n",
    "    if error < 0.83:\n",
    "        y_pred_best = y_pred\n",
    "    print(error)\n",
    "print(min(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d6a9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.index(min(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9794a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors.index(min(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88447fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(50, 20), dpi=50)\n",
    "ax1.tick_params(axis='y', which='both',    \n",
    "                labeltop='on', labelbottom='off', labelsize=27)\n",
    "ax1.tick_params(axis='x', labelbottom='off', labelsize=27)\n",
    "ax1.grid()\n",
    "ax1.plot(y_pred_best, lw=3, color='orange')\n",
    "ax1.plot(y_test, lw=3, color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a136b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(y_pred_best, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9c51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred1 = regr1.predict(X_train)\n",
    "y_train_pred2 = regr2.predict(X_train)\n",
    "y_train_pred3 = regr3.predict(X_train)\n",
    "\n",
    "\n",
    "ensamble_train_X = [[y_train_pred1[i], y_train_pred2[i], y_train_pred3[i]] for i in range(len(y_train_pred1))]\n",
    "regr_ens = MLPRegressor().fit(ensamble_train_X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c49eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred1 = regr1.predict(X_test)\n",
    "y_test_pred2 = regr2.predict(X_test)\n",
    "y_test_pred3 = regr3.predict(X_test)\n",
    "ensamble_test_X = [[y_test_pred1[i], y_test_pred2[i], y_test_pred3[i]] for i in range(len(y_test_pred1))]\n",
    "y_pred = regr_ens.predict(ensamble_test_X)\n",
    "corr = abs(np.corrcoef(y_pred, y_test)[0][1])\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b26be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pricesSup = pd.read_csv('./supplemental_files/stock_prices.csv', parse_dates=[\"Date\"])\n",
    "pricesSup = prepare_data(pricesSup)\n",
    "pricesSup = pricesSup.replace({'SecuritiesCode' : new_codes})\n",
    "pricesSup = create_diffs(pricesSup)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for date in pricesSup.Date.unique():\n",
    "        x = torch.Tensor(pricesSup.loc[pricesSup.Date==date, [*features]].to_numpy()).to(device)\n",
    "        pred = model(x)\n",
    "        pricesSup.loc[pricesSup.Date==date, \"Prediction\"] = pred.cpu().detach().numpy()\n",
    "        pricesSup.loc[pricesSup.Date==date, \"Rank\"] = pricesSup.loc[pricesSup.Date==date, \"Prediction\"].rank(ascending=False, method=\"first\") - 1\n",
    "        pricesSup.loc[pricesSup.Date==date, \"Rank\"] = pricesSup.loc[pricesSup.Date==date, \"Rank\"].astype(\"int\")\n",
    "\n",
    "sharpe_ratio, buf = calc_spread_return_sharpe(pricesSup)\n",
    "sharpe_ratio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
