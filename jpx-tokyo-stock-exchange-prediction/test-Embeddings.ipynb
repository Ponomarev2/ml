{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2197a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import *\n",
    "from datetime import datetime\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b94be7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [[0, 1, 1], [1,1,1]]\n",
    "y_train = [1,0]\n",
    "X_test = [[0, 1, 1], [1,1,1]]\n",
    "y_test = [1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a208de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.Tensor(X)\n",
    "        self.y = torch.Tensor(y).unsqueeze(1)\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd17cdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchSize = 1\n",
    "dataset_train = Dataset(X_train, y_train)\n",
    "dataset_test = Dataset(X_test, y_test)\n",
    "train_dl = torch.utils.data.DataLoader(dataset_train, batch_size=batchSize, shuffle=False)\n",
    "test_dl = torch.utils.data.DataLoader(dataset_test, batch_size=batchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "11ab3292",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(MLP, self).__init__()\n",
    "        emb_size = 8\n",
    "        self.layer1 = Linear(emb_size+n_inputs, 10)\n",
    "        self.layer2 = Linear(10, 10)\n",
    "        self.layer3 = Linear(10, 1)\n",
    "        self.activation = LeakyReLU()\n",
    "        self.embedding = torch.rand([3, emb_size], requires_grad=True).to(device)\n",
    "\n",
    " \n",
    "    def forward(self, X):\n",
    "        codes = X[:, 0].long()\n",
    "        X = X[:, 1:]\n",
    "        emb = self.embedding[codes]\n",
    "        X = torch.cat((X, emb), 1)\n",
    "        X = self.activation(self.layer1(X))\n",
    "        X = self.layer3(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fbab4872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6d938a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, min_lr=1e-6, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "43d505df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train loss: tensor(0.2777, device='cuda:0', grad_fn=<DivBackward0>), eval loss: tensor(0.0656, device='cuda:0')\n",
      "Epoch: 100, train loss: tensor(3.5533e-06, device='cuda:0', grad_fn=<DivBackward0>), eval loss: tensor(3.7253e-06, device='cuda:0')\n",
      "0:00:00.298257\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(101):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for i, (inputs, targets) in enumerate(train_dl):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        yhat = model(inputs)\n",
    "        loss = criterion(yhat, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(test_dl):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            yhat = model(inputs)\n",
    "            loss = criterion(yhat, targets)\n",
    "            eval_loss += loss\n",
    "        \n",
    "    #scheduler.step(eval_loss)\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print(\"Epoch: \" + str(epoch) + \", train loss: \" + str(train_loss/len(train_dl)) + \", eval loss: \" + str(eval_loss/len(test_dl)))\n",
    "\n",
    "print(datetime.now() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "db42fade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1.],\n",
      "        [1., 1., 1.]]) tensor([[1.],\n",
      "        [0.]])\n",
      "tensor([[ 0.9975],\n",
      "        [-0.0011]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (inputs, targets) in enumerate(test_dl):\n",
    "        print(inputs, targets)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        yhat = model(inputs)\n",
    "        print(yhat)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda87e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6f9ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
